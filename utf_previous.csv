thread_id,email_id,email_code,previous_email_id,previous_email_body,previous_email_code
152625,156564,uncivil,156500,"So I hate this rst crap with a passion, so NAK from me.",uncivil
152625,156500,uncivil,152625,"Let PDF & HTML's be created out of memory-barriers Text by restructuring.  restructuring done were, 1. Section headers modification, lower header case except start 2. Removal of manual index(contents section), since it now gets created    automatically for html/pdf 3. Internal cross reference for easy navigation 4. Alignment adjustments 5. Strong emphasis made wherever there was emphasis earlier (through    other ways), strong was chosen as normal emphasis showed in italics,    which was felt to be not enough & strong showed it in bold 6. ASCII text & code snippets in literal blocks 7. Backquotes for inline instances in the paragraph's where they are    expressed not in English, but in C, pseudo-code, file path etc. 8. Notes section created out of the earlier notes 9. Manual numbering replaced by auto-numbering 10.Bibliography (References section) made such that it can be cross-linked.   Hi,  With this change, pdf & html could be generated. There certainly are improvements to be made, but thought of first knowing whether migrating memory-barriers from txt to rst is welcome.  The location chosen is Documentation/kernel-hacking"", i was unsure where this should reside & there was no .rst file in top-level directory ""Documentation"", so put it into one of the existing folder that seemed to me as not that unsuitable.  Other files refer to memory-barrier.txt, those also needs to be adjusted based on where .rst can reside.      ",technical
152625,156871,uncivil,156614,"Hi, If necessary to handle these, symlink might help here i believe.  Upon trying to understand memory-barriers.txt, i felt that it might be better to have it in PDF/HTML format, thus attempted to convert it to rst. And i see it not being welcomed, hence shelving the conversion.",technical
152625,157636,civil,156871,"IMO symlinks are mostly ending in a mess, URLs are never stable. There is a      to handle such requirements. Take a look at *intersphinx* :     to see how it works:  Each Sphinx HTML build creates a file named objects.inv that contains a mapping from object names to URIs relative to the HTML sets root.  This means articles from external (like lwn articles) has to be recompiled. Not perfect, but a first solution.    I really like them, factually valuable comments .. please express your concern so that we have a chance to move on.   I think that's a pity. ",uncivil
159308,177720,uncivil,177719,"Hi,  After this patch user-space can trigger an SError in the guest. If it wants to migrate the guest, how does the pending SError get migrated?  I think we need to fix migration first. Andrew Jones suggested using KVM_GET/SET_VCPU_EVENTS:   Given KVM uses kvm_inject_vabt() on v8.0 hardware too, we should cover systems without the v8.2 RAS Extensions with the same API. I think this means a bit to read/write whether SError is pending, and another to indicate the ESR should be set/read. CPUs without the v8.2 RAS Extensions can reject pending-SError that had an ESR.  user-space can then use the 'for migration' calls to make a 'new' SError pending.  Now that the cpufeature bits are queued, I think this can be split up into two separate series for v4.16-rc1, one to tackle NOTIFY_SEI and the associated plumbing. The second for the KVM 'make SError pending' API.    Does nothing in the patch that adds the support? This is a bit odd. (oh, its hiding in patch 6...)",technical
161354,161783,uncivil,161722,Thanks for adding the comment. ,technical
165231,165261,civil,165230,"One of the limitations of pm_runtime_force_suspend/resume() is that if a parent driver wants to use these functions, all of its child drivers generally have to do that too because of the parent usage counter manipulations necessary to get the correct state of the parent during system-wide transitions to the working state (system resume). However, that limitation turns out to be artificial, so remove it.  Namely, pm_runtime_force_suspend() only needs to update the children counter of its parent (if there's is a parent) when the device can stay in suspend after the subsequent system resume transition, as that counter is correct already otherwise.  Now, if the parent's children counter is not updated, it is not necessary to increment the parent's usage counter in that case any more, as long as the children counters of devices are checked along with their usage counters in order to decide whether or not the devices may be left in suspend after the subsequent system resume transition.  Accordingly, modify pm_runtime_force_suspend() to only call pm_runtime_set_suspended() for devices whose usage and children counters are at the no references"" level (the runtime PM status of the device needs to be updated to ""suspended"" anyway in case this function is called once again for the same device during the transition under way), drop the parent usage counter incrementation from it and update pm_runtime_force_resume() to compensate for these changes. ",technical
165657,169349,uncivil,165657," There's a risk that a kernel that has full retpoline mitigations becomes vulnerable when a module gets loaded that hasn't been compiled with the right compiler or the right option.  We cannot fix it, but should at least warn the user when that happens.  When the a module hasn't been compiled with a retpoline aware compiler, print a warning and change the SPECTRE_V2 mitigation mode to show the system is vulnerable now.  For modules it is checked at compile time, however it cannot check assembler or other non compiled objects used in the module link.  v2: Change warning message v3: Port to latest tree v4: Remove tainting 		add_depends(&buf, mod, modules), --""",technical
166193,168161,uncivil,168038,tested v3... ,technical
167856,174594,civil,174357,"I think we need to think over what is a good way to share ownership of a pin.  Russell pointed me to a similar problem incidentally and I briefly looked into it: there are cases when several devices may need to hold the same pin.  Can't we just look up the associated gpio_chip from the GPIO range, and in case the pin is connected between the pin controller and the GPIO chip, then we allow the gpiochip to also take a reference?  I.e. in that case you just allow gpio_owner to proceed and take the pin just like with a non-strict controller. ",technical
168060,169219,uncivil,168063,Test the new MEMBARRIER_CMD_PRIVATE_EXPEDITED_SYNC_CORE and MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED_SYNC_CORE commands.,technical
168169,173259,civil,173260,"FWIW, SLCG stands for second level clock gating",technical
168668,168727,uncivil,168726,"boutside protection'?  In general I'd rather have the tracepoints when actually submitting the request, with this tracepoint we might be getting a trace which doesn't really indicate if the command was submitted at all.",technical
169133,177084,uncivil,169133,"In drivers/net/wan/hdlc_ppp.c, some noise on physical line can cause the carrier detect still ok, but the protocol will fail. So if carrier detect ok, don't turn off protocol negotiation  This patch is against the kernel version Linux 4.15-rc8",technical
169133,177642,uncivil,177133,"The timer is supposed to be triggered by carrier detect interrupt. After remove the line noise, the carrier detect interrupt is never triggered again, because the carrier is always ok and it only trigger the timer once, Since the protocol was terminated and no new interrupts happen, the link will never be back. So the case here is that the line noise is good and just good to make the carrier detect still good  but the protocol fail, the timer will be never triggered again.  Of course, if you increase the noise and make even the carrier detect fail, then remove the noise, the link will be up, Because the carrier down and up again and then trigger the timer to restart. The timer is supposed to restart the protocol again, that's how this whole thing is designed to work.  I think you are making changes to the symptom rather than the true cause of the problems you are seeing.  Sorry, I will not apply this until the exact issue is better understood.",technical
169133,179802,civil,177642,"Ok, I check the source code again. It have nothing to do with the interrupts, it is related how the hdlc.c is implemented. It will do nothing, not start any new protocol and thus the timer.   My case is the carrier always good, but protocol will fail due to perfect noise, and this issue was found and complained by our customers. So it is not my theory guessing, it is a real problem.  The timer is supposed to restart the protocol again, that's how this whole thing is designed to work.  I think you are making changes to the symptom rather than the true cause of the problems you are seeing.  Sorry, I will not apply this until the exact issue is better understood.",uncivil
169133,193114,civil,179802,"Sorry about being late, just returned home and am trying to get all the backlogs under control.  I remember the PPP standard is a bit cloudy about the possible issue, but the latter indeed exists (the PPP state machine was written directly to STD-51). There is related (more visible in practice, though we aren't affected) issue of active"" vs ""passive"" mode (hdlc_ppp.c is ""active"", and two ""passives"" wouldn't negotiate at all).  Anyway the problem is real (though not very visible in practice, especially on relatively modern links rather than 300 or 1200 bps dialup connections) and should be fixed. Looking at the patch, my first impression is it makes the code differ from STD-51 a little bit. On the other hand, perhaps applying it as is and forgetting about the issue is the way to go.  Ideally, I think the negotiation failure should end up (optionally, in addition to the current behavior) in some configurable sleep, then the negotiation should restart. If it's worth the effort at this point, I don't know.  Perhaps I could look at this later, but no promises (this requires pulling on and setting up some legacy hardware).  Anyway, since the patch is safe and can solve an existing problem: ",civil
169133,204633,uncivil,203117,"Hi, David:  How  is your thinking about this patch? Subject: [PATCH] netdev: carrier detect ok, don't turn off negotiation   Sometimes when physical lines have a just good noise to make the protocol  handshaking fail, but the carrier detect still good. Then after remove of  the noise, nobody will trigger this protocol to be start again to cause  the link to never come back. The fix is when the carrier is still on, not  terminate the protocol handshaking.  Ok, I submit it  again.   In drivers/net/wan/hdlc_ppp.c, some noise on physical line can cause the carrier detect still ok, but the protocol will fail. So if carrier detect ok, don't turn off protocol negotiation  This patch is against the kernel version Linux 4.15-rc8 Please resubmit it and I'll think about it again, thank you.",technical
170193,170197,uncivil,170198,Add basic self-test functionality for pmalloc.,technical
170193,188751,uncivil,170195,Well this introduces significant overhead for large sized allocation. Does this not matter because the areas are small?  Would it not be better to use compound page allocations here? page_head(whatever) gets you the head page where you can store all sorts of information about the chunk of memory.,technical
170193,188745,civil,190492,"Hi Igor,  Thank you for the patch! Yet something to improve:",technical
173287,173288,uncivil,173287,iio_dev->mlock is to be used only by the IIO core for protecting device mode changes between INDIO_DIRECT and INDIO_BUFFER.  This patch replaces the use of mlock with the already established buf_lock mutex. ,technical
174463,174508,uncivil,174487, I already sent a fix for this:,technical
174735,174850,uncivil,174736,"Export and import are mandatory in async hash. As drivers were rewritten, drop empty wrappers and correct init of ahash transformation. ",technical
174735,199553,uncivil,199556,All applied.  Thanks. ,technical
174735,199600,uncivil,199597,"The bug can only be in driver which will not implement those two functions, but we already had all drivers with those due to patches 1..4 All other drivers do have them.  Additionally, with crypto we want minimize code and run as fast as possible.  Moving checks out of core will impose on driver author need for implement those functions, or declare them empty, but in case of empty ones  crypto will not work properly with such driver. ",technical
174735,199673,uncivil,199600,"The core can very well check if these functions are not populated and return ENOSYS   So you remove all NULL pointer checks ? Esp. in security-sensitive code? What is the impact of this non-critical path code on performance?  Come on ...   You can very well impose that in the core, except you don't duplicate the code. ",uncivil
174735,199701,uncivil,199673,"Why you want checks for something that not exist ?  Those without them will not work and will do Oops in crypto testmgr, so such drivers should not be used nor accepted in drivers/crypto  Ask yourself why crypto do not check for NULL in ahash digest or other required ahash functions.   Now size of crypto core is reduced. ",uncivil
174735,200015,uncivil,199976,"It is source code duplication. One do not load all crypto drivers at once, simple because one board has only one crypto HW (or few closely related), and if one even try, almost none of them will initialize on given hardware. E.g. on Exynos board only exynos drivers will load, on board with omap crypto only omap crypto will load.    As I said above, it reduces binary size at cost of more source code in few drivers. ",uncivil
174735,199976,uncivil,199701,"Are you suggesting that the kernel code should NOT perform NULL pointer checks ?  Are you suggesting each driver should implement every single callback available and if it is not implemented, return -ENOSYS ? This looks like a MASSIVE code duplication.   You implemented the same code thrice, it surely is not reduced. ",uncivil
180488,180837,civil,180546,"This doesn't make much sense to me, to be honest. We are holding mmap_sem for _read_ so we allow parallel updates like page faults or unmaps. Therefore we are isolating pages prior to the migration.  The sole purpose of the mmap_sem in add_page_for_migration is to protect from vma going away _while_ need it to get the proper page.  Moving the lock up is just wrong because it allows caller to hold the lock for way too long if a lot of pages is migrated. Not only that, it is even incorrect because we are doing get_user() (aka page fault) and while read lock recursion is OK, we might block and deadlock when there is a writer pending. I haven't checked the current implementation of semaphores but I believe we do not allow recursive locking.",technical
183468,183472,civil,183473,"stable: 62 boots: 0 failed, 58 passed with 2 offline, 2 untried/unknown Full Boot Summary. For more info write to ",technical
202437,202446,uncivil,202444,"The variables dssdev"" and ""vid_dev"" will eventually be set to appropriate pointers a bit later. Thus omit the explicit initialisations at the beginning.  ",technical
202437,505099,uncivil,202446,Use normal patch styles. Fix your tools before you send any more patches.,uncivil
202437,505195,uncivil,505193,"Interesting. Would you like to share any more information from this meeting?    I would appreciate further indications for a corresponding change acceptance.  I found a feedback by Mauro Carvalho Chehab more constructive. Cleanup fixes. This time, I was nice and I took some time doing",uncivil
202437,505193,uncivil,505158,For the record: this only applies to drivers/media. We discussed what do to with series like this during our media summit last Friday and this was the conclusion of that. Obviously I can't talk about other subsystems.,technical
202437,513970,uncivil,505225,I have got an other impression.    I continued with the presentation of suggestions from my selection of change possibilities. It seems that there are very different expectations for the preferred patch granularity.  Can it happen again that you are going to use a development tool like quilt (as a maintainer) for the desired recombination of possible update steps?,technical
202437,745390,uncivil,513970,I find it very surprising that you rejected 146 useful update suggestions so easily.    What does this software area make it so special in comparison to other Linux subsystems?    * Have you taken any other solution approaches into account than   a quick rejection?  * Could your reaction have been different if the remarkable number of   change possibilities were sent by different authors (and not only me)?  * How should possibly remaining disagreements about affected implementation   details be resolved now?  * Are you looking for further improvements around development tools   like patchwork and quilt?  * Will you accept increasing risks because of bigger patch sizes?    * Can such an information lead to differences in the preferred patch granularity?  * How do you think about this detail?    How would you ever like to clean up stuff in affected source files which was accumulated (or preserved somehow) over years?    I guess that this handling will trigger more communication challenges.    Our common sense seems to be occasionally different in significant ways.    I distribute my software development capacity over several areas. Does your wording indicate a questionable signal for further contributions?,uncivil
202437,160227,uncivil,745390,Would you like to answer my still remaining questions in any more constructive ways?,uncivil
202437,191235,uncivil,160227,Are you going to answer any of my remaining questions in a more constructive way?,uncivil
202437,191241,uncivil,191235,Do any contributors get into the mood to take another look at software updates from my selection of change possibilities in a more constructive way?  Do you need any additional development resources?,uncivil
202437,191275,uncivil,191241,"One last time: either post per-driver patches with all the cleanups for a driver in a single patch, or a per-directory patch (drivers/media/pci, usb, etc) doing the same cleanup for all drivers in that directory.  I prefer the first approach, but it's up to you.  We don't have the time to wade through dozens of one-liner cleanup patches.  I don't understand what is so difficult about this.",uncivil
202437,196318,uncivil,191275,"I preferred to offer source code adjustments according to specific transformation patterns mostly for each software module separately (also in small patch series).    I am curious if bigger patch packages would be easier to get accepted.  Or would you get frightened still by any other change combination?     We have got different preferences for a safe patch granularity.    I imagine that there are more development factors involved.    It is usual that integration of update suggestions will take some time. How would the situation change if I would dare to regroup possible update steps?    There are communication difficulties to consider since your terse information from your conference meeting.  If you would insist on patch squashing, would you dare to use a development tool like quilt fold also on your own once more?",uncivil
207400,207934,civil,207917,"Andrew,  You didn't miss it - I probably need to explain it better.  The 'emulated devices' do respond on different slave addresses (which match one of or the only the slave addresses those parts support). For example the device-tree for the GW54xx has the following which are all from the GSC which is the only thing on i2c1 One issue I'm trying to figure out the best way to deal with is the fact that the GSC can 'NAK' transactions occasionally which is why I override the regmap read/write functions and provide retries. This resolves the issue for the mfd core driver and sub-module drivers but doesn't resolve the issue with these 'emulated devices' which have their own stand-alone drivers. I'm not sure how to best deal with that yet. I tried to add retires to the i2c adapter but that wasn't accepted upstream because it was too generic and I was told I need to work around it in device-drivers. I'm guessing I need to write my own sub-module drivers that will largely duplicate whats in the stand-alone drivers.""",technical
207400,208102,civil,208059,Hi Tim  There appears to be a few spaces vs tabs issues in this file.,technical
207400,208141,civil,208102,"Hi Dmitry - thanks for the review!   ok   ok - will have this in v2. oops, did not mean to submit that   it was for original debugging and not needed - will remove   Yes, that makes sense. I'll propose something like the following in. right - thanks!   I am using request_threaded_irq with thread_fn with thread_fn (vs handler).  Do you mean why use a work procedure? I guess I don't need that and can call input_report_key directly from the irq.   ok   can you point me to an example dts/driver?  Tim",civil
207400,208159,civil,208144,Thanks. I'll run through checkpatch prior to v2.,technical
210458,210459,uncivil,210458,"debugfs_real_fops() returns a NULL pointer when it is invoked without a prior call to debugfs_file_get(). In code paths including this call it is not strictly necessary to check the return value of debugfs_real_fops(). However clang inlines debugfs_real_fops(), detects the invalid dereferencing of the NULL pointer and drops the code path. This leads to a bunch of objtool warnings when building with clang,  Check the pointer returned by debugfs_real_fops() in all code paths to make clang and objtool happy.  ",technical
210458,210461,uncivil,210467,"Or, as the case may be, oopsing at the point of failure.    --",technical
210458,210463,uncivil,210462," Thanks all for your input, we'll try to get -fno-delete-null-pointer-checks or a similar flag to be added to",technical
216128,216133,civil,216131,"The old_serial_port global array in 8250_core is supposed to hold an entry for each serial port on the system that cannot be discovered via a standard enumeration mechanism (aka ACPI/PCI/DTS).  The array is populated at compile-time from the value specified in the SERIAL_PORT_DFNS macro. This macro is defined in arch/serial.h.  For x86, this macro is currently unconditionally initialized to supply four ioport UARTs (0x3F8, 0x2F8, 0x3E8, 0x2E8).  However, not all x86 CPUs have these four ioport UARTs.  For example, the UARTs on AMD Carrizo and later are separate memory mapped Designware IP blocks.  Fairly early in boot the console_initcall univ8250_console_init iterates over this array and installs these old UARTs into the global array serial8250_ports.  Further, it attempts to register them for use as the console.  In other words, if, for example, the kernel commandline has console=ttyS0, the console will be switched over to one of these non-existent UARTs.  Only later, when the real UART drivers are probed and their devices are instantiated will the console switch back over to the proper UART.  This is noticeable when using earlycon, since part of the serial console log will appear to disappear (when the bogus old takes over) and then re-appear (when the real UART finally gets registered for the console).  The problem is even more noticable when *not* using earlycon, since in this case the entire console output is missing, having been incorrectly played back to the non-existing serial port.  Create a global variable to allow skipping old serial port initialization and wire it up to the AMDCZ ACPI SPCR quirk and the special amdcz earlycon setup handler.  ",technical
216128,216130,civil,216132,"Hi Daniel,  Thank you for the patch! Yet something to improve:  [if your patch is applied to the wrong git tree, please drop us a note to help improve the system",technical
221804,221853,uncivil,221804,"Add Amiga Gayle PATA controller driver. It enables libata support for the on-board IDE interfaces on some Amiga models (A600, A1200, A4000 and A4000T) and also for IDE interfaces on the Zorro expansion bus (M-Tech E-Matrix 530 expansion card).  Thanks to John Paul Adrian Glaubitz and Michael Schmitz for help with testing the driver. ",technical
222860,223021,uncivil,223039,"Hi,    How many times are we going to allow copy-and-pasting the same driver? Last time we wanted to modify the Rockchip driver, we were told consolidate"", because ST had already forked our driver. This nearly halted all progress. I'm going to be real disappointed if we see another fork get merged.  (IOW, I would say ""over my dead body,"" but I have no power here.)  And why can't you use DRM?""",uncivil
222860,230472,civil,224687,Does this use driver model? I cannot see it.,technical
230843,231058,civil,231041,"Right, ok. That's a problem.  This means that you are relying on get_module_plt() being called at least once at module load time, which is not guaranteed.  Instead, you should set this member (and perhaps the entire prealloc routine) in a module_finalize() implementation.",technical
231231,232204,civil,232201,"There is no limit on CPU equivalence table length in this patch series like it was in the previous version.  The maximum possible value returned by install_equiv_cpu_table() of comes from the maximum value of this 'size' variable (that is UINT_MAX) plus the header length of CONTAINER_HDR_SZ. This won't fit in 'int' type, hence this patch.  That's because this functions tells its caller how much bytes to skip from the beginning of a microcode container file to the first patch section contained in it.",technical
232313,234089,uncivil,232313,"there are 2 reasons for no need to wait device probe  reason 1: mount root device is very late in kernel initial stage. all initcalls are finished. that means most of probe functions are returned.  and deferred probe are also finished by late_initcall. only async probe driver are possible in  probing.  no block devices, device-mapper or nfs are use async probe. so no need to wait device probe.  reason 2: let's check dd.c, probe_count is increased and decreased only in really_probe, and when really_probe returns, probe_count always be 0.  when someone really wants to wait device-B probe. but code looks like:",technical
239101,240255,uncivil,240077,"Hi Milan, I will run veritysetup test on next version of these patches and contact you about verity-compat-test testsuits.",technical
239101,240572,civil,240255,"They've been dropped.  BUT please do note that the patches I pushed to linux-dm.git were rebased ontop of the 'check_at_most_once' patch.  I never did get an answer about how the sg array is free'd in certain error paths (see FIXME:"" in the 2nd patch).  Also, I fixed some issues I saw in error paths, and lots of formatting.  I'll be pretty frustrated if you submit v2 that is blind to the kinds of changes I made.  I'll send you a private copy of the patches just so you have them for your reference.""",uncivil
245912,245922,uncivil,245963,This commit adds a maintainer information for the PECI subsystem.,technical
245912,245953,civil,245922,"Is this include needed?   Please use bool.   I am quite completely missing how the two functions above are different.   There is a lot of duplication in those functions. Would it be possible to find common code and use functions for it instead of duplicating everything several times ?   What if nothing is found ?   FWIW, it might be better to pass channel - DEFAULT_CHANNEL_NUMS as parameter.  What if find_core_index() returns priv->gen_info->core_max, ie if it didn't find a core ?   This attribute should not exist.   lcrit is tcontrol - tjmax, and crit_hyst above is tjmax - tcontrol ? How does this make sense ?   Am I missing something, or is the same temperature reported several times ? tjmax is also reported as temp_crit cputemp_read_die(), for example.   There is again a lot of duplication in those functions.   Can this be made less magic with some defines ?   Does this mean there will be an error message for each non-supported CPU ? Why ?   -ENODEV is not an error, and should not result in an error message. Besides, the error can also be propagated from peci core code, and may well be something else.   Then what ? Shouldn't this result in probe deferral or something more useful instead of just being ignored ?   FWIW, this should be two separate patches.   Needed ?   It might make sense to provide the duplicate functions in a core file.   This again looks like duplicate code.   Please handle error cases first.   More duplicate code.   One set of ( ) is unnecessary on each side of the expression.   Why is this invalid"", and why does it warrant an error message ?   Is priv->addr guaranteed to be >= PECI_BASE_ADDR ?  Or the peci command failed.   cancel_delayed_work_sync() ?""",uncivil
245912,245916,uncivil,245939,"Additionally, I need to explain that there is one and only bus host (adapter) and multiple clients on a PECI bus, and PECI spec doesn't allow multiple originators so only the host device can originate message. In this implementation, all message transactions on a bus from client driver modules and user space will be serialized well in the PECI core bus driver so bus occupation and traffic arbitration will be managed well in the PECI core bus driver even in case of a bus has 2  client drivers at the same address. I'm sure that this implementation  doesn't make that kind of problem to OS.",technical
254985,255085,uncivil,254985,"Page replacement is handled in the Linux Kernel in one of two ways:  1) Asynchronously via kswapd 2) Synchronously, via direct reclaim  At page allocation time the allocating task is immediately given a page from the zone free list allowing it to go right back to work doing whatever it was doing, Probably directly or indirectly executing business logic.  Just prior to satisfying the allocation, free pages is checked to see if it has reached the zone low watermark and if so, kswapd is awakened. Kswapd will start scanning pages looking for inactive pages to evict to make room for new page allocations. The work of kswapd allows tasks to continue allocating memory from their respective zone free list without incurring any delay.  When the demand for free pages exceeds the rate that kswapd tasks can supply them, page allocation works differently. Once the allocating task finds that the number of free pages is at or below the zone min watermark, the task will no longer pull pages from the free list. Instead, the task will run the same CPU-bound routines as kswapd to satisfy its own allocation by scanning and evicting pages. This is called a direct reclaim.  The time spent performing a direct reclaim can be substantial, often taking tens to hundreds of milliseconds for small order0 allocations to half a second or more for order9 huge-page allocations. In fact, kswapd is not actually required on a linux system. It exists for the sole purpose of optimizing performance by preventing direct reclaims.  When memory shortfall is sufficient to trigger direct reclaims, they can occur in any task that is running on the system. A single aggressive memory allocating task can set the stage for collateral damage to occur in small tasks that rarely allocate additional memory. Consider the impact of injecting an additional 100ms of latency when nscd allocates memory to facilitate caching of a DNS query.  The presence of direct reclaims 10 years ago was a fairly reliable indicator that too much was being asked of a Linux system. Kswapd was likely wasting time scanning pages that were ineligible for eviction. Adding RAM or reducing the working set size would usually make the problem go away. Since then hardware has evolved to bring a new struggle for kswapd. Storage speeds have increased by orders of magnitude while CPU clock speeds stayed the same or even slowed down in exchange for more cores per package. This presents a throughput problem for a single threaded kswapd that will get worse with each generation of new hardware.  Test Details  NOTE: The tests below were run with shadow entries disabled. See the associated patch and cover letter for details  The tests below were designed with the assumption that a kswapd bottleneck is best demonstrated using filesystem reads. This way, the inactive list will be full of clean pages, simplifying the analysis and allowing kswapd to achieve the highest possible steal rate. Maximum steal rates for kswapd are likely to be the same or lower for any other mix of page types on the system.  Tests were run on a 2U Oracle X7-2L with 52 Intel Xeon Skylake 2GHz cores, 756GB of RAM and 8 x 3.6 TB NVMe Solid State Disk drives. Each drive has an XFS file system mounted separately as /d0 through /d7. SSD drives require multiple concurrent streams to show their potential, so I created 11 250GB zero-filled files on each drive so that I could test with parallel reads.  The test script runs in multiple stages. At each stage, the number of dd tasks run concurrently is increased by 2. I did not include all of the test output for brevity.  During each stage dd tasks are launched to read from each drive in a round robin fashion until the specified number of tasks for the stage has been reached. Then iostat, vmstat and top are started in the background with 10 second intervals. After five minutes, all of the dd tasks are killed and the iostat, vmstat and top output is parsed in order to report the following:  CPU consumption - sy - aggregate kernel mode CPU consumption from vmstat output. The value doesn't tend to fluctuate much so I just grab the highest value. Each sample is averaged over 10 seconds - dd_cpu - for all of the dd tasks averaged across the top samples since            there is a lot of variation.  Throughput - in Kbytes - Command is total  This first test performs reads using O_DIRECT in order to show the maximum throughput that can be obtained using these drives. It also demonstrates how rapidly throughput scales as the number of dd tasks are increased.  The dd command for this test looks like this> Throughput was close to peak with only 22 dd tasks. Very little system CPU was consumed as expected as the drives DMA directly into the user address space when using direct IO.  In this next test, the iflag=direct option is removed and we only run the test until the pgscan_kswapd from /proc/vmstat starts to increment. At that point metrics are parsed and reported and the pagecache contents are dropped prior to the next test. Lather, rinse, repeat.  Each read has to pause after the buffer in kernel space is populated while those pages are added to the pagecache and copied into the user address space. For this reason, more parallel streams are required to achieve peak throughput. The copy operation consumes substantially more CPU than direct IO as expected.  The next test measures throughput after kswapd starts running. This is the same test only we wait for kswapd to wake up before we start collecting metrics. The script actually keeps track of a few things that were not mentioned earlier. It tracks direct reclaims and page scans by watching the metrics in /proc/vmstat. CPU consumption for kswapd is tracked the same way it is tracked for dd.  Since the test is 100% reads, you can assume that the page steal rate for kswapd and direct reclaims is almost identical to the scan rate. In the previous test where kswapd was not involved, the system-wide kernel mode CPU consumption with 90 dd tasks was 16%. In this test CPU consumption with 90 tasks is at 43%. With 52 cores, and two kswapd tasks (one per NUMA node), kswapd can only be responsible for a little over 4% of the increase. The rest is likely caused by 51,618 direct reclaims that scanned 1.2 billion pages over the five minute time period of the test.  Same test, more kswapd tasks:  By increasing the number of kswapd threads, throughput increased by ~50% while kernel mode CPU utilization decreased or stayed the same, likely due to a decrease in the number of parallel tasks at any given time doing page replacement. allows you to control the number of kswapd threads per node +running on the system. This provides the ability to devote additional CPU +resources toward proactive page replacement with the goal of reducing +direct reclaims. When direct reclaims are prevented, the CPU consumed +by them is prevented as well. Depending on the workload, the result can +cause aggregate CPU usage on the system to go up, down or stay the same. + +More aggressive page replacement can reduce direct reclaims which cause +latency for tasks and decrease throughput when doing filesystem IO through +the pagecache. Direct reclaims are recorded using the allocstall counter +in /proc/vmstat. + +The default value is 1 and the range of acceptible values are 1-16. +Always start with lower values in the 2-6 range. Higher values should +be justified with testing. If direct reclaims occur in spite of high +values, the cost of direct reclaims (in latency) that occur can be +higher due to increased lock contention. ",technical
258997,259457,uncivil,258997,"Hi, Linus,  Please pull from git:// next  to receive the latest Thermal Management updates for v4.17-rc1 with top-most commit?  Merge branches 'thermal-core' and 'thermal-soc' into next on top of commit: Specifics:  - Fix race condition in imx_thermal_probe().  Add cooling device's statistics in sysfs.  add support for i.MX7 thermal sensor in imx_thermal driver. add support for MT7622 SoC in mtk_thermal driver. Remove unused min/max cpu cooling DT property.A series of fixes on exynos driver. ",technical
258997,259513,civil,259457,"Pulled, and then immediately unpulled again.  The code causes new compiler warnings, and the warnings are valid.  If people don't care enough about their code to even check the warnings, I'm not going to waste one second pulling the resulting garbage. It's that simple.",uncivil
258997,260177,uncivil,260171,"Hi,   Since this condition cannot happen (the driver makes sure of this during probe) I would prefer much simpler fix from Arnd:    (I've already ACKed it two weeks ago).   ditto",technical
258997,260189,uncivil,260184,It is okay to return 0 because this code-path (the default one) will be never hit by the driver (probe makes sure of it) - the default case is here is just to silence compilation errors..,technical
258997,260193,civil,260189,The init function is making sure cal_type is one or another. Can you fix it correctly by replacing the 'switch' by a 'if' instead of adding dead branches to please gcc?,uncivil
259276,259299,uncivil,259276,"de4x5_hw_init() is never called in atomic context.  de4x5_hw_init() is only called by de4x5_pci_probe(), which is only  set as .probe"" in struct pci_driver.  Despite never getting called from atomic context, de4x5_hw_init()  calls mdelay() to busily wait. This is not necessary and can be replaced with usleep_range() to  avoid busy waiting.  This is found by a static analysis tool named DCNS written by myself. And I also manually check it.",technical
259276,259489,civil,259487,"James is right, You have added all usleep_range() during system boot-up  time. During boot-up system will run as single threaded. Where this change will not make much sense. System first priority is match the exact timing on each and every boot-up.  ",technical
261377,261389,uncivil,261377,Upstream commit  Make calibration register value fixed  makes ina2xx_set_shunt() call mutex_lock on an un-initialized mutex. Initialize it prior so we don't get a NULL pointer dereference error  ,technical
261866,263843,uncivil,261868,This patch adds missing stuff to support multislot mode in DesignWare MMC driver.  The main changes:  * Add missing slot switch to __dw_mci_start_request() function.  * Refactor set_ios function:    a) Calculate common clock which is       suitable for all slots instead of directly use clock value       provided by mmc core. We calculate common clock as the minimum       among each used slot clocks. This clock is calculated in       dw_mci_calc_common_clock() function which is called       from set_ios()    b) Disable clock only if no other slots are ON.    c) Setup clock directly in set_ios() only if no other slots       are ON. Otherwise adjust clock in __dw_mci_start_request()       function before slot switch.    d) Move timings and bus_width setup to separate funcions.  * Use timing field in each slot structure instead of common field in    host structure.  * Add locks to serialize access to registers.  NOTE: this patch is based off of v4.17-rc1  NOTE: as of today I tested this changes (in singleslot and multislot    modes) only on Synopsys HSDK board. But I will get ODROID-XU4 board    (with Exynos5422 which has DW MMC controller) the next week    so I will test it on this board too to catch any regressions. ,technical
266017,266025,uncivil,266017,"On an ASRock E350M1, with Linux 4.17-rc1 according to `initcall_debug` calling `azx_driver_init` takes sometimes more than a few milliseconds, and up to 200 ms.  returned 0 after 49195 usecs ```  Trying to execute the Linux kernel in less than 500 ms, this is quite a hold-up, and therefore request the probe from an async task.  With this change, the test shows, that the function returns earlier.  The same behavior is visible on a Dell OptiPlex 7010. The longer times seem to happen, when the module *e1000e* is probed during the same time.  ",technical
266017,266029,civil,266025,What actually took so long?  Could you analyze further instead of blindly putting the flag?,uncivil
266279,266313,uncivil,266296,"code->index can be controlled by user-space, hence leading to a potential exploitation of the Spectre variant 1 vulnerability.  Smatch warning: Fix this by sanitizing code->index before using it to index codes.  Notice that given that speculation windows are large, the policy is to kill the speculation on the first load and not worry if it can be completed with a dependent load/store",technical
266279,266331,civil,266313,"Please enlighten me: how do you think this could be exploited?  When an application calls VIDIOC_ENUM_FMT from a /dev/video0 device, it will just enumerate a hardware functionality, with is constant for a given hardware piece.  The way it works is that userspace do something like:   in order to read an entire const table.  Usually, it doesn't require any special privilege to call this ioctl, but, even if someone changes its permission to 0x400, a simple lsusb output is enough to know what hardware model is there. A lsmod or cat /proc/modules) also tells that the tm6000 module was loaded, with is a very good hint that the tm6000 is there or was there in the past.  In the specific case of tm6000, all hardware supports exactly the same formats, as this is usually defined per-driver. So, a quick look at the driver is enough to know exactly what the ioctl would answer.  Also, the net is full of other resources that would allow anyone to get the supported formats for a piece of hardware.  Even assuming that the OS doesn't have lsusb, that /proc is not mounted, that /dev/video0 require special permissions, that the potential attacker doesn't have physical access to the equipment (in order to see if an USB board is plugged), etc... What possible harm he could do by identifying a hardware feature?  Similar notes for the other patches to drivers/media in this series: let's not just start adding bloatware where not needed.  Please notice that I'm fine if you want to submit potential Spectre variant 1 fixups, but if you're willing to do so, please provide an explanation about the potential threat scenarios that you're identifying at the code.  Dan,  It probably makes sense to have somewhere at smatch a place where we could explicitly mark the false-positives, in order to avoid use to receive patches that would just add an extra delay where it is not needed.""",uncivil
266279,266334,civil,266331,I see I've missed some obvious things that you've pointed out here. I'll  mark these warnings as False Positives and take your points into account  for the analysis of the rest of the Spectre issues reported by Smatch.  Sorry for the noise and thanks for the feedback.,civil
266279,267299,civil,266764,"Just had a better look at v4l_fill_fmtdesc() and actually read the comment. The code cannot be compiled as a array because it is big and sparse. But the log(n) condition tree is a prime candidate for the branchscope side-channel, which would be able to reconstruct a significant number of bits of the original value. A denser tree gives more bits etc.",technical
266918,267111,civil,266918,"The method ndo_start_xmit() is defined as returning an 'netdev_tx_t', which is a typedef for an enum type, but the implementation in this driver returns an 'int'.  Fix this by returning 'netdev_tx_t' in this driver too.",technical
266918,269136,uncivil,267111,"Luc please don't submit such a huge number of patches all at one time.  Also, please fix the indentation of the functions whose arguments span multiple lines as has been pointed out to you in patch feedback.  Finally, make this a true patch series.  It is so much easier for maintainers to work with a set of changes all doing the same thing if you make them a proper patch series with an appropriate [PATCH 0/N] ..."" header posting.""",civil
281311,281957,uncivil,281311,"The write operation to hotplug->enabled"" is protected by the lock on line 1760, but the read operation to this data on line 1755 is not protected by the lock. Thus, there may exist a data race for ""hotplug->enabled"".  To fix this data race, the read operation to ""hotplug->enabled"" is  also protected by the lock.",technical
281311,283024,uncivil,282919,"I only read the code and find this possible data race. It is not found in real driver execution. I am not sure of it, so I use may"" and ""possible"" here.""",technical
289026,291846,civil,291684,That looks a lot better. Thanks for giving it a go.,technical
289026,292549,civil,292515,"Thank you for your feedback. That makes sense, surplus hugepages are charged to both memcg and hugetlb cgroup, which may be contrary to cgroup design philosophy.  Based on the above advice, I have considered the following improvements, what do you think about?  The 'charge_surplus_hugepages' of v2 patch-set was an option to switch whether to charge memcg in addition to hugetlb cgroup"", but it will be abolished. Instead, change to ""switch only to memcg instead of hugetlb cgroup"" option. This is called 'surplus_charge_to_memcg'.  The surplus_charge_to_memcg option is created in per hugetlb cgroup. If it is false(default), charge destination cgroup of various page types is the same as the current kernel version. If it become true, hugetlb cgroup stops accounting for surplus hugepages, and memcg starts accounting instead.  A table showing which cgroups are charged.  I stared at the commit log of mm/hugetlb_cgroup.c, but it did not seem to have specially considered of surplus hugepages. Later, I will send a mail to hugetlb cgroup's committer to ask about surplus hugepages charge specifications. ",technical
289026,292839,uncivil,292549,"I am sorry that I didn't join the discussion for the previous version but time just didn't allow that. So sorry if I am repeating something already sorted out.   There was a deliberate decision to keep hugetlb and normal"" memory cgroup controllers separate. Mostly because hugetlb memory is an artificial memory subsystem on its own and it doesn't fit into the rest of memcg accounted memory very well. I believe we want to keep that status quo.   Well such a usecase requires an explicit configuration already. Either by using special wrappers or modifying the code. So I would argue that you have quite a good knowlege of the setup. If you need a greater flexibility then just do not use hugetlb at all and rely on THP. [...]   I do not really think this is a good idea. We really do not want to make the current hugetlb code more complex than it is already. The current hugetlb cgroup controller is simple and works at least somehow. I would not add more on top unless there is a _really_ strong usecase behind. Please make sure to describe such a usecase in details before we even start considering the code.   Well, then I would argue that you shouldn't use 64kB pages for your setup or allow THP for smaller sizes. Really hugetlb pages are by no means a substitute here.",civil
289026,294078,civil,294072,"Thank you for your time.  I do not know if it is really a strong use case, but I will explain my motive in detail. English is not my native language, so please pardon my poor English.  I am one of the developers for software that managing the resource used from user job at HPC-Cluster with Linux. The resource is memory mainly. The HPC-Cluster may be shared by multiple people and used. Therefore, the memory used by each user must be strictly controlled, otherwise the user's job will runaway, not only will it hamper the other users, it will crash the entire system in OOM.  Some users of HPC are very nervous about performance. Jobs are executed while synchronizing with MPI communication using multiple compute nodes. Since CPU wait time will occur when synchronizing, they want to minimize the variation in execution time at each node to reduce waiting times as much as possible. We call this variation a noise.  THP does not guarantee to use the Huge Page, but may use the normal page. This mechanism is one cause of variation(noise).  The users who know this mechanism will be hesitant to use THP. However, the users also know the benefits of the Huge Page's TLB hit rate performance, and the Huge Page seems to be attractive. It seems natural that these users are interested in HugeTLBfs, I do not know at all whether it is the right approach or not.  At the very least, our HPC system is pursuing high versatility and we have to consider whether we can provide it if users want to use HugeTLBfs.  In order to use HugeTLBfs we need to create a persistent pool, but in our use case sharing nodes, it would be impossible to create, delete or resize the pool.  One of the answers I have reached is to use HugeTLBfs by overcommitting without creating a pool(this is the surplus hugepage).  Surplus hugepages is hugetlb page, but I think at least that consuming buddy pool is a decisive difference from hugetlb page of persistent pool. If nr_overcommit_hugepages is assumed to be infinite, allocating pages for surplus hugepages from buddy pool is all unlimited even if being limited by memcg. In extreme cases, overcommitment will allow users to exhaust the entire memory of the system. Of course, this can be prevented by the hugetlb cgroup, but even if we set the limit for memcg and hugetlb cgroup respectively, as I asked in the first mail(set limit to 10GB), the control will not work.  I thought I could charge surplus hugepages to memcg, but maybe I did not have enough knowledge about memcg. I would like to reply to another mail for details.   Actually, I am opposed to the 64KB page, but the proposal to change the page size is expected to be dismissed as a problem. ",technical
289026,271213,civil,294650,"Note.  You do not want to use THP because THP does not guarantee"".   Using hugetlbfs overcommit also does not provide a guarantee.  Without doing much research, I would say the failure rate for obtaining a huge page via THP and hugetlbfs overcommit is about the same.  The most difficult issue in both cases will be obtaining a ""huge page"" number of pages from the buddy allocator.  I really do not think hugetlbfs overcommit will provide any benefit over THP for your use case.  Also, new user space code is required to ""fall back"" to normal pages in the case of hugetlbfs page allocation failure.  This is not needed in the THP case. ",technical
289431,289688,civil,271302,"XFS never uses the block device mapping for anything, so this is not needed.   The proper name for this would be vfs_sync_fs.  And I don't think it warrants an inline.",technical
289431,292003,uncivil,271303,"Thanks, I wasn't sure about xfs. I'll drop this hunk.  FWIW, I think pushing this call down into the sync_fs routines is still probably the right thing to do, regardless of the state of the later patches.   I patterned the name after the call_mmap (and now-defunct call_fsync) helpers. I'll rename it and change it to be non-inlined.",technical
303621,305468,uncivil,304654,"The X11 license notice states explicitly that the notice has to be included in the file.  Wouldn't removing it be a violation of the license?    FYI, this was copied from another .dts file.  All of the other brightness-levels settings in sun files follow similar patterns:",technical
306145,317171,civil,317094,"Hi Andrew  thanks for the hint. But actually I cannot confirm - or I don't see it yet.     Without having tested, just from the code, the struct phy_driver instance for PHY_ID_KSZ8061 in micrel.c does not have a .write_mmd function assigned, thus phy_write_mmd should evaluate to its else-clause (see below) and not to mdiobus_write (as in phy_write).    Also the ksz8061_extended_write() function which I have added uses the same principle as already existing HW-specific functions in micrel.c for simular reasons (kszphy_extended_write and ksz9031_extended_write).  They use phy_write all over the place in that file and never phy_write_mmd - for whatever reason they had.  Thus I thought it would be a good idea ...    PHY link failure after cable connect. Hi Alexander    This looks a lot like phy_write_mmd(). ",technical
306145,357688,uncivil,357674,"Hi Andrew  thanks for your feedback. I was on holiday, thus just delayed, not forgotten... Sorry for top-posting - odd company default mail setup. I checked again phy_write_mmd(), you are right !  Patch with changed implementation will follow.  PHY link failure after cable connect. Hi Alexander  Please don't top post. And wrap your lines at around 75 characters. Look closely at the two implementations. Look at what mmd_phy_indirect() does. I _think_ these are identical. So don't add your own helper, please use the core code.",technical
307410,307390,civil,307830,"When remote files are counted in get_files_count, without using SSH, the code returns 0 because there is a colon prepended to $LOC. $VPATH should have been used instead of $LOC.(NTB: ntb_test: Update ntb_tool Scratchpad tests"") ",technical
307410,311549,civil,311538,"I disagree strongly. You can tell it's not device specific seeing we have 4 devices that need the exact same code. In fact, there is nothing device specific in those lines of code as the device specific part comes when a driver sets the PCI parent device's DMA mask. These lines just initialize the dma_mask for the new NTB device with its parent's mask. This is just sensible given that nothing now works if it is not done and trusting driver writers to get it right is not a good idea seeing we already screwed it up once. Furthermore, it violates DRY (do not repeat yourself).  If there is something driver specific that must be done (although I can't actually imagine what this would be) the drivers are free to change the mask after calling ntb_register but getting the common case setup in common code is just good design.",technical
307410,349339,uncivil,314425,Thanks. It would be good to get Acked-bys or Reviewed-bys on the patches you approved.,technical
310967,311378,uncivil,310967,"When i2c_new_dummy fails, the lack of error-handling code may cause unexpected results.  This patch adds error-handling code after calling i2c_new_dummy.  ",technical
314071,314224,civil,314071,"FALLOC_FL_NO_HIDE_STALE flag must be set if user want to issue a discard request for block devices. But vfs_fallocate() will return with an error -EOPNOTSUPP indicating lack of support if this flag is set.  fix it by allowing  flag in vfs_fallocate  Fixes: (block: implement (some of) fallocate for block devices"") 	",technical
331266,331355,uncivil,331349,Same problem here :(,technical
331266,331694,uncivil,331356,No changelog :(,technical
331266,331847,uncivil,331710,"Oh come on, putting a basic here is what this patch does"" comment should be part of every patch, otherwise what is there to comment on if we don't know what is going on in the patch itself?  Anyway, I provided a bunch of feedback to the ""real"" patch in this series...""",uncivil
331266,331710,uncivil,331694,"Greg (and replying to your other comments as well)...  This is an RFC series, it's not meant for you to take at this point, it's about discussing the overall approach to exposing BMC random tunables"" as explained in patch 0 of the series.  Yes the individual patches aren't yet at the level of polish for a formal submission, we (naively ?) thought that's what the whole RFC tag is about :-)""",uncivil
336834,337035,uncivil,336834,"Analyzing the circular locking dependency splat [2], I can see the following skeleton/pattern:  is trying to acquire lock X.     *same* has previously acquired lock Y.     lock Y depends on lock X (hence chance for deadlock).      Print lock dependency chain Print an example of potential scenario leading to real deadlock.     List all locks held by. Print backtrace (seems to be equal to <stack-dump-0>). The following questions appeared in my mind when analyzing [2]: (A) What is the chronology of consuming the locks? Is it related to     the order seen in the ""dependency chain""? (B) All four locks are reported to be held by the same task.     Indeeed, based on available backtraces, 3 of 4 are acquired     during the load of cpufreq_dt.ko by systemd-udevd. However,     there is a different syscall behind ""cpu_hotplug_lock.rw_sem"" which     made we wonder if it is really systemd-udevd consuming this lock. If     not, is it still correct to say that systemd-udevd holds all locks? (C) The example of potential unsafe scenario leading to deadlock     puts a special emphasis on the CPU on which the lock is held.     However, except for the last held lock  whose CPU can be extracted from  there is no CPU-related information for the other locks. doesn't match the stack backtrace of ""cpu_hotplug_lock.rw_sem""     (there is no cpufreq_register_driver() call in the backtrace).     Maybe I misinterpret the report? ",technical
336834,337316,uncivil,337035,"Yeah, not going to happen. You grow that structure from 64 bytes to 96 bytes and with that grow the static footprint of the kernel by 512k (in the very best case) possibly again breaking things like sparc (which have a strict limit on the kernel image size).  And all that for data that I've never needed and never even considered useful when looking at lockdep output.",uncivil
346223,347267,civil,346227,"For kexec_file loading, if kexec_buf.top_down is 'true', the memory which is used to load kernel/initrd/purgatory is supposed to be allocated from top to down. This is what we have been doing all along in the old kexec loading interface and the kexec loading is still default setting in some distributions. However, the current kexec_file loading interface doesn't do like this. The function arch_kexec_walk_mem() it calls ignores checking kexec_buf.top_down, but calls walk_system_ram_res() directly to go through all resources of System RAM from bottom to up, to try to find memory region which can contain the specific kexec buffer, then call locate_mem_hole_callback() to allocate memory in that found memory region from top to down. This brings confusion especially when KASLR is widely supported , users have to make clear why kexec/kdump kernel loading position is different between these two interfaces in order to exclude unnecessary noises. Hence these two interfaces need be unified on behaviour.  Here add checking if kexec_buf.top_down is 'true' in arch_kexec_walk_mem(), if yes, call the newly added walk_system_ram_res_rev() to find memory region from top to down to load kernel. ",technical
347183,348381,civil,347502,"Hm, a runtime PM ref is already acquired in nouveau_connector_detect(). I'm wondering why that's not sufficient?",technical
347183,349692,civil,348395,"As an additional note, I realized this might seem wrong but it isn't  pm_runtime_put_sync() calls down to nouveau's runtime idle callback, which does this:  static int nouveau_pmops_runtime_idle(struct device *dev)   So, it doesn't actually synchronously suspend the GPU, it just starts up the autosuspend thread  Just wanted to make sure there wasn't any confusion :)  --",technical
358863,358900,uncivil,358863,"When you e.g. run `find` on a directory for which getdents returns filenames"" that contain slashes, `find` passes those ""filenames"" back to the kernel, which then interprets them as paths. That could conceivably cause userspace to do something bad when accessing something like an untrusted USB stick, but I'm not aware of any specific example.  Instead of returning bogus filenames to userspace, return -EUCLEAN.  ",technical
365796,367116,uncivil,367099,"Hi!    That's rather long and verbose way to describe a bitmap, right?   Is rbtree good idea? You don't have that many registers.  ....  No error checking required here?   This checks if we have just one bank, I see it. Should it also check the led actually uses the correct bank?   Is not the fwnode_handle_put() done twice for non-error case?   The if is not needed here.   Misleading, this does nothing with regulators.  			",technical
365796,367141,civil,367140,"Yes, and LED strings are statically assigned to banks, right?  So why not simply forget about LED strings for sake of hw abstractions, and work just with banks? ",technical
365796,367690,civil,367623,"Dan,    led-sources was designed for describing the topology where one LED can be connected to more then one output, see bindings of max77693-led (in Documentation/devicetree/bindings/mfd/max77693.txt).  Here the topology is a bit different - more than one LED (string) can be connected to a single bank, but this is accomplished inside the chip. Logically LEDs configured that way can be treated as a single LED (string) connected to two outputs, and what follows they should be described by a single DT child node.  led-sources will fit very well for this purpose. You could do the following mapping: Then, in the child DT nodes you would use these identifiers to describe the topology:  Following node would describe strings connected to the outputs HVLED1 and HVLED2 controlled by bank A.",technical
365796,367764,uncivil,367698,"Jacek and Pavel,  I agree to use the led-sources but I still believe this approach may be confusing to other sw devs and will lead to configuration issues by users.  This implementation requires the sw dev to know which strings are controlled by which bank. And this method may produce a misconfiguration like something below where HVLED2 is declared in both bank A and bank B.  The driver will need to be intelligent and declare a miss configuration on the above. Not saying this cannot be done but I am not sure why we want to add all of these extra LoC and intelligence in the kernel driver. The driver cannot make assumptions on the intention.  And the device tree documentation will need to pretty much need a lengthy explanation on how to configure the child nodes.  The implementation I suggested removes that ambiguity.  It is a simple integer that is written to the device as part of the device configuration, which the config is a setting for the device.  The child nodes denote which bank the exposed LED node will control.  Removing any need for the sw developers new or old to know the specific device configurations. ",technical
368515,368789,civil,368520,Extend sample-parsing test cases to support new sample type PERF_SAMPLE_PAGE_SIZE.  ,technical
372597,372959,uncivil,372597,"The tap_queue and the tap_dev"" are loosely coupled, not ""macvlan_dev"".  And I also change one rcu_read_lock's place, seems can reduce rcu critical section a little. ",technical
374095,374559,civil,374095,"Even though we protect on-flash data by CRC checksums, we still don't trust the media. If lnum is not 0 or 1, access exceed array boundary can lead to bad situation.  ",technical
377230,377461,civil,377229,"Running the AIM7 fserver workload on a 2-socket 24-core 48-thread Broadwell system, it was found that there were severe spinlock contention in the XFS code. In particular, native_queued_spin_lock_slowpath() consumes 69.7% of cpu time. The xlog_grant_head_check() function call and its sub-function calls underneath it consumed 27.2% of the cpu time. This function tried to wake up tasks in the log space wait queue and then put itself into the wait queue if there is not enough log space left.  The process of waking up task can be time consuming and it is not really necessary to hold an XFS lock while doing the wakeups. So the xlog_grant_head_wake() function is modified to put the tasks to be waken up into a wake_q to be passed to wake_up_q() without holding the lock.  Corresponding changes are made in xlog_grant_head_wait() to dequeue the tasks from the wait queue after they are put into the wake_q. This avoids multiple wakeups of the same task from different log space waiters. Multiple wakeups seems to be a possibility in the existing code too.  With the use of the wake_q, the cpu time used by native_queued_spin_lock_slowpath() dropped to 39.6%. However, the performance of the AIM7 fserver workload increased from 91,485.51 jobs/min to 397,290.21 jobs/min which was more than 4X improvement.  ",technical
377230,378511,civil,378176,"You are right. The XFS filesystem was created on a small ramfs device and so the disk space was tiny. The microbenchmark that I used exposes some extreme cases that may not be normally observed.   Those were part of the perf trace that I marked down:   A spurious wakeup shouldn't change the behavior as the waiter should find that it is still being queued (list not empty) and so will sleep again. However, if the waiter is rightfully waken but find that there is not enough log space somehow, it will put itself back to the end of the queue. That is a change in behavior that I think could be an issue.  I am just wondering why the code doesn't reserve the actual log space at the time a task is being waken. Instead, it has to try to get it itself after being waken.  Also I think the current code allows consecutive waiters to come in and wake up the same set of tasks again and again. That may be where a part of the performance slowdown come from.   As I said above, spurious wakeup shouldn't cause problem. However, consecutive waiters will probably wake up more tasks than there is log space available. In this case, some of the tasks will be put back to the queue. Maybe a counter to record the log space temporarily reserved for the waken-up task can help to prevent over-subscription.    The wake_q should work correctly as it is used by mutexes and rwsems. We will see a lot of problem reports if that is not the case.   That is probably true.   I am using a old git (1.8). I should probably upgrade to a newer one.   OK   It is because the wake_q uses a field in the task structure for queuing. So a task can only be in one wake_q at a time. Leaving the ticket in the queue may cause the task to be put into multiple wake_q causing missed wakeup, perhaps.    Yes, you are right. The xlog_grant_head_wake_all() need to be modified as well.   OK, I need more time to think about some of the questions that you raise.  Thanks for reviewing the patch.",technical
378505,378562,uncivil,378507,"In the current log space reservation slowpath code, the log space waiters are waken up by an incoming waiter while holding the lock. As the process of waking up a task can be time consuming, doing it while holding the lock can make spinlock contention, if present, more severe.  This patch changes the slowpath code to use the wake_q for waking up tasks without holding the lock, thus improving performance and reducing spinlock contention level.  Running the AIM7 fserver workload on a 2-socket 24-core 48-thread Broadwell system with a small xfs filesystem on ramfs, the performance increased from 192,666 jobs/min to 285,221 with this change. ",technical
378505,379417,civil,379318,"Yes, I realise that.  I am expecting that when it comes to optimising for pmem, we'll actually rewrite the journal to map pmem and memcpy() directly rather than go through the buffering and IO layers we currently do so we can minimise write latency and control concurrency ourselves. Hence I'm not really concerned by performance issues with pmem at this point - most of our still users have traditional storage and will for a long time to come....",technical
379138,379657,civil,379138,"Currently in record mode the tool implements trace writing serially.  The algorithm loops over mapped per-cpu data buffers and stores ready  data chunks into a trace file using write() system call.  At some circumstances the kernel may lack free space in a buffer  because the other buffer's half is not yet written to disk due to  some other buffer's data writing by the tool at the moment.  Thus serial trace writing implementation may cause the kernel  to loose profiling data and that is what observed when profiling  highly parallel CPU bound workloads on machines with big number  of cores.  Experiment with profiling matrix multiplication code executing 128  threads on Intel Xeon Phi (KNM) with 272 cores, like below, demonstrates data loss metrics value of 98%: Data loss metrics is the ratio lost_time/elapsed_time where  lost_time is the sum of time intervals containing PERF_RECORD_LOST  records and elapsed_time is the elapsed application run time  under profiling.  Applying asynchronous trace streaming thru Posix AIO API  lowers data loss  metrics value providing ~25% improvement in average.  ",technical
383199,392690,uncivil,383199,Using checkpatch.pl I was able to find a multiline dereference which goes again the coding style for the kernel. I'm still working on my email client so the indentation looks bad here (in gmail) but the arguments for comedi_check_trigger_arg_min should go just under the opening ,technical
390394,390741,civil,390396,"Since the size is now fixed, there is no need to include the tfm argument. This removes it from the definition and callers.   --",technical
391895,394633,civil,392481,"Hi, Please document both of these kernel parameters in Documentation/admin-guide/kernel-parameters.txt.",technical
391895,397297,uncivil,396847,"Here is an extra"" patch containing bug fixes and warning removals, that I have accumulated up to this point.  It goes on top of the other 60 patches. (When it is time for v2, these fixes will be integrated into the appropriate patches within the series.)  The changes are:  1. Avoid a hang with nested scheduled task groups. 2. Get rid of a lockdep warning. 3. Get rid of warnings about missed clock updates. 4. Get rid of ""untested code path"" warnings/reminders (after testing    said code paths).  This should make experimenting with this patch series a little less bumpy.  ",technical
391895,397649,uncivil,397297,"I don't call this non-intrusive.   I'll beg to differ, this isn't anywhere near something to consider merging. Also 'happened' suggests a certain stage of completeness, this again doesn't qualify.   There are known scalability problems with the existing cgroup muck, you just made things a ton worse. The existing cgroup overhead is significant, you also made that many times worse.  The cgroup stuff needs cleanups and optimization, not this.    That is the whole and only reason you did this, and it doesn't even begin to cover the requirements for it.  Not to mention I detest cgroups, for their inherent complixity and the performance costs associated with them.  _If_ we're going to do something for L1TF then I feel it should not depend on cgroups.  It is after all, perfectly possible to run a kvm thingy without cgroups.   Note that in order to avoid PLE and paravirt spinlocks and paravirt tlb-invalidate you have to gang-schedule the _entire_ VM, not just SMT siblings.  Now explain to me how you're going to gang-schedule a VM with a good number of vCPU threads (say spanning a number of nodes) and preserving the rest of CFS without it turning into a massive trainwreck?  Such things (gang scheduling VMs) _are_ possible, but not within the confines of something like CFS, they are also fairly inefficient because, as you do note, you will have to explicitly schedule idle time for idle vCPUs.  Things like the Tableau scheduler are what come to mind, but I'm not sure how to integrate that with a general purpose scheduling scheme. You pretty much have to dedicate a set of CPUs to just scheduling VMs with such a scheduler.  And that would call for cpuset-v2 integration along with a new scheduling class.  And then people will complain again that partitioning a system isn't dynamic enough and we need magic :/  (and this too would be tricky to virtualize itself)   You gloss over a ton of details here, many of which are non trivial and marked broken in your patches. Unless you have solid suggestions on how to deal with all of them, this is a complete non-starter.  The per-cpu IRQ/steal time accounting for example. The task timeline isn't the same on every CPU because of those.  You now basically require steal time and IRQ load to match between CPUs. That places very strict requirements and effectively breaks virt invariance. That is, the scheduler now behaves significantly different inside a VM than it does outside of it -- without the guest being gang scheduled itself and having physical pinning to reflect the same topology the coschedule=1 thing should not be exposed in a guest. And that is a mayor failing IMO.  Also, I think you're sharing a cfs_rq between CPUs: that is broken, the virtual runtime stuff needs nontrivial modifications for multiple CPUs. And if you do that, I've no idea how you're dealing with SMP affinities.   You don't even begin to outline how you preserve smp-nice fairness.   IOW it's completely friggin useless for L1TF.   Have you actually read your own code?  What about that atrocious locking you sprinkle all over the place? 'some additional lock contention' doesn't even begin to describe that horror show.  Hint: we're not going to increase the lockdep subclasses, and most certainly not for scheduler locking.   All in all, I'm not inclined to consider this approach, it complicates an already overly complicated thing (cpu-cgroups) and has a ton of unresolved issues while at the same time it doesn't (and cannot) meet the goal it was made for.",uncivil
399771,400133,uncivil,399771,"When link status change needs to be committed and rtnl lock couldn't be taken, avoid redisplay of same link status change message.  ",technical
399771,401526,uncivil,401073,"Thanks Eric for reviewing the patch. rtnl_needed is not a shared variable, it is part of bonding structure, that is one per bonding driver instance. There can't be two parallel instances of bond_miimon_inspect for a single  bonding driver instance at any given point of time. and only bond_miimon_inspect updates it. That's why I think there is no need of any synchronization here.    Thank you for cautioning us on bool usage. even a u8 can meet our requirement.  we will change it.  but, if time permits can you share more on particularly dangerous here, at least on some arches"".""",technical
402510,413538,uncivil,413483,There is a hunk a bit lower in the patch where in perf_pmu_register the  initial setting is assigned from the global sysctl.   Sure!,technical
402510,413650,uncivil,413538,"Tvrtko,  It would be very helpful if you cc all involved people on the cover letter instead of just cc'ing your own pile of email addresses. CC'ed now.   This is really not helpful. The cover letter and the change logs should contain a summary of that discussion and a proper justification of the proposed change. Just saying 'sysadmins might want to allow' is not useful at all, it's yet another 'I want a pony' thing.  I read through the previous thread and there was a clear request to involve security people into this. Especially those who are deeply involved with hardware side channels. I don't see anyone Cc'ed on the whole series.  For the record, I'm not buying the handwavy 'more noise' argument at all. It wants a proper analysis and we need to come up with criteria which PMUs can be exposed at all.  All of this want's a proper documentation clearly explaining the risks and scope of these knobs per PMU. Just throwing magic knobs at sysadmins and then saying 'its their problem to figure it out' is not acceptable.",uncivil
402510,413698,uncivil,413650,"Hi,    I accept it was by bad to miss adding Cc's on the cover letter, but my  own email addresses hopefully should not bother you. It is simply a  question of what I have in .gitconfig vs what I forgot to do manually.   Okay, for the next round I will expand the cover letter with at least  one concrete example on how it is usable and summarize the discussion a bit.   Who would you recommend I add? Because I really don't know..   Presumably you see adding fine grained control as diminishing the  overall security rather than raising it? Could you explain why? Because  incompetent sysadmin will turn it off for some PMU, while without having  the fine-grained control they wouldn't turn it off globally?  This feature was requested by the exact opposite concern, that in order  to access the i915 PMU, one has to compromise the security of the entire  system by allowing access to *all* PMU's.  Making this ability fine-grained sounds like a logical solution for  solving this weakening of security controls.  Concrete example was that on video transcoding farms users want to  monitor the utilization of GPU engines (like CPU cores) and they can do  that via the i915 PMU. But for that to work today they have to dial down  the global perf_event_paranoid setting. Obvious improvement was to allow  them to only dial down the i915.perf_event_paranoid setting. As such,  for this specific use case at least, the security is increased.",uncivil
402510,413768,uncivil,413698,"Tvrtko,    The keyword in the above sentence is 'just'. You can add as many of yours as you want as long as everybody else is cc'ed.   Sure, and because you don't know you didn't bother to ask around and ignored the review request.  I already added Kees and Jann. Please look for the SECCOMP folks in MAINTAINERS.   I did not say at all that this might be diminishing security. And the argumentation with 'incompetent sysadmins' is just the wrong attitude.  What I was asking for is proper documentation and this proper documentation is meant for _competent_ sysadmins.  That documentation has to clearly describe what kind of information is accessible and what potential side effects security wise this might have. You cannot expect that even competent sysadmins know offhand what which PMU might expose. And telling them 'Use Google' is just not the right thing to do.  If you can't explain and document it, then providing the knob is just fulfilling somebodys 'I want a pony' request.   Sure, and this wants to be documented in the cover letter and the changelogs.  But this does also require a proper analysis and documentation why it is not a security risk to expose the i915 PMU or what potential security issues this can create, so that the competent sysadmin can make a judgement.  And the same is required for all other PMUs which can be enabled in the same way for unprivileged access. And we might as well come to the conclusion via analysis that for some PMUs unpriviledged access is just not a good idea and exclude them. I surely know a few which qualify for exclusion, so the right approach is to provide this knob only when the risk is analyzed and documented and the PMU has been flagged as candidate for unpriviledged exposure. I.e. opt in and not opt out.",uncivil
402510,413778,uncivil,413776,Which paranoia level would be used for the i915.perf_event_paranoid setting in such a case?  Perhaps also CC  on the next version.,technical
402510,414000,uncivil,413936,"Alexey,    Just to make it clear. I'm not against separate settings at all. But I'm against adding knobs for every PMU the kernel supports wholesale without analysis and documentation just because we can and somebody wants it.  Right now we have a single knob, which is poorly documented and that should be fixed first. But some googling gives you the information that allowing unprivilegded access is a security risk. So the security focussed sysadmin will deny access to the PMUs no matter what.  Now we add more knobs without documentation what the exposure and risk of each PMU is. The proposed patch set does this wholesale for every PMU supported by the kernel. So the GPU user will ask the sysadmin to allow him access. How can he make an informed decision? If he grants it then the next user comes around and wants it for something else arguing that the other got it for the GPU already. How can he make an informed decision about that one?  We provide the knobs, so it's also our responsibility towards our users to give them the information about their usage and scope. And every single PMU knob has a different scope.  The documentation of the gazillion of knobs in /proc and /sysfs is not really brilliant, but we should really not continue this bad practice especially not when these knobs have potentially security relevant implcations. Yes, I know, writing documentation is work, but it's valuable and is appreciated by our users.  To make this doable and not blocked by requiring every PMU to be analyzed and documented at once, I suggested to make this opt-in. Do analysis for a given PMU, decide whether it should be exposed at all. If so, document it proper and flip the bit. That way this can be done gradually as the need arises and we can exclude the riskier ones completely.  I don't think this is an unreasonable request as it does not require the i915 folks to look at PMUs they are not familiar with and does not get blocked by waiting on every PMU wizard on the planet to have time.  Start with something like Documentation/admin-guide/perf-security.rst or whatever name fits better and add a proper documentation for the existing knob. With the infrastructure for fine grained access control add the general explanation for fine grained access control. With each PMU which opt's in for the knob, add a section with guidance about scope and risk for this particular one.",technical
402510,414266,uncivil,414076,"Ah, I guess the answer is 0"", since you want to see data about what other users are doing.  Does the i915 PMU expose sampling events, counting events, or both? The thing about sampling events is that they AFAIK always let the user pick arbitrary data to collect - like register contents, or userspace stack memory -, and independent of the performance counter being monitored, this kind of access should not be permitted to other contexts. (But it might be that I misunderstand how perf works - I'm not super familiar with its API.)""",technical
410867,414489,uncivil,410867,"The method ndo_start_xmit() is defined as returning an 'netdev_tx_t', which is a typedef for an enum type, so make sure the implementation in this driver has returns 'netdev_tx_t' value, and change the function return type to netdev_tx_t.  Found by coccinelle",technical
422694,423291,uncivil,422694,"In preparation to enabling -Wimplicit-fallthrough, mark switch cases where we are expecting to fall through.  Notice that in this particular case, I replaced ...and fall through."" with a proper ""fall through"", which is what GCC is expecting to find.  Addresses-Coverity-ID: 1462408 (""Missing break in switch"") ",technical
422694,428645,uncivil,428602,"Thanks, Jonathan. Below are some examples of cases in which the fall-through warning turned out to be an actual bug:  So, yeah. This effort is worth it.",technical
424089,424518,uncivil,424089," During testing, I have configured 128 md/raid1's and, while under heavy IO, I started a check on each of them. The CPU utilization went through the ceiling and when looking for the cause (with 'perf top'). I've discovered that ~50% of the time was spend in memcmp() called from process_checks().  With this patch applied, it drops to 4% - 10%.",technical
467091,471421,uncivil,470763,"My point is, I don't get the relationship between your patch and secondary-master/slave-mode support.   I maintain that functionally, I3C is closer to USB than I2C. That does not mean that it's competing with USB performance-wise, it just means that the SW stack is likely to resemble the USB one (probably a bit simpler, at least at the beginning).    Look at the bus discovery mechanism, the notion of DCR (close to the concept of USB class), or the fact that each dev has a unique manufacturer+PID pair (which resemble the product/vendor ID concept) that allows us to easily bind a dev to a driver without requiring a static description.   That's called USB OTG. Okay, to be fair, it's not exactly the same, and the mastership handover in I3C is probably more complex than what we have with USB OTG (I'm not a USB expert, so I might be wrong here).   Maybe.   So you have such a dual-role controller? I mean, Cadence IP has a dummy GPIO mode in its Master IP when is operating in slave mode (secondary master, or main master after it's released the bus), but I'm not sure this was designed for anything else but testing.  What I call a slave controller would be something that lets you reply to SDR/DDR transactions or fill a generic regmap that would be exposed to other masters on the bus. This way we could implement generic slave drivers in Linux (the same way we have gadget drivers). Anything else is likely to be to specific to be exposed as a generic framework.   Hm, not sure I like this idea either. So I see 2 options:  1/ put all controller drivers (both master and slave ones) in a common  directory as you suggest, and prefix them    correctly  2/ place them in separate directories: drivers/i3c/{master,slave,dual}  I'm fine either way.   I think I understand your concerns now, but only because you started to mention a few things that were not clearly stated before (at least, I didn't understand it this way), like the fact that your controller (and probably others too) supports dual-role, or the fact that you plan to expose your IP through the PCI bus.",technical
467091,471458,uncivil,471421,"Hi Boris     The major feature close to USB is this one and it can be found in others  protocols (standardization process).  Just to close this topic I3C vs USB, IMO it's wrong to pass the message  that the I3C is closer to USB than I2C even more because I3C support the  I2C on the fly.     Sorry, with the proliferation of sensors I cannot see a multi master  sensor network based on USB.     Yes, we already talked about secondary master support.     I would bet to do something like in i2c, we don't need the same level of  complexity found in USB.     I agree with the controller folder but not with prefix. Please check  what is already in the kernel.     In this case and taking what is already in the kernel it will be  drivers/i3c/{master, slave, dwc, other with the same architecture as dwc}.     I miss to mention PCI but since the beginning refer the slave and the  common part.  Splitting the driver is something that soon or later I will have to do.  If you prefer later I'm ok with that.   I think this discussion is starting to be counterproductive with arguing  of both parts. Unfortunately I don't see anyone given their inputs too.  To be clear, the subsystem is nice and I working with daily. As I said  this is something that I dealing now and I'm telling what I think that  is not correct.",uncivil
467091,479249,uncivil,478983,"Hi Boris,   Sorry for the delayed response.      I think this should be discuss in another thread. Do you agree?     Yes, that was what I trying to tell you. For me this might be the best  option.  I would like to avoid having dual role i3c driver in a master folder.     I don't disagree, and for those that have more than one file they should  be in a folder, right?  What prefix do you have in mind for those files inside a folder?     No, it's not. But as you can see to slipt the driver in parts this  subject has some relevance.",technical
476403,477115,uncivil,476592,Adding the current maintainers on CC.  ,technical
476403,477136,uncivil,477115,So I strongly disagree with this. Anybody that has trouble with 0/1 vs false/true needs to stay the heck away from C.  I would suggest we delete that stupid coccinelle scripts that generates these pointless warns.,uncivil
476403,478120,uncivil,477173,"Personally, I would prefer that assignments involving boolean variables use true or false.  It seems more readable.  Potentially better for tools as well.  But if the community really prefers 0 and 1, then the test can be deleted.",technical
498594,573986,uncivil,573878,"Ping? Jonathan, can you pick this up?  ",technical
498594,573990,uncivil,573986,What's advertisement there?   Huch? Care to tell what's a lie instead of making bold statements?,uncivil
498594,574206,civil,573990,"No problem here, no performance issues, nothing to be seen unless you are running VM.""   Take a care to look at the patch I submitted?  Lie:  # A system with an up to date kernel is protected against attacks from # malicious user space applications.  3GB system running 32bit kernel is not protected. Same is true for for really big 64bit systems.  If I do what dmesg suggests, this becomes untrue:  # The Linux kernel contains a mitigation for this attack vector, PTE # inversion, which is permanently enabled and has no performance # impact.  Limiting memory to 2GB _is_ going to have severe performance impact. ",uncivil
498594,574882,uncivil,574206,"I would really like to get an ack from the people who have been deep into this first.  If you can get that, and preferably resubmit with a less condescending changelog, I can pick it up.",civil
498594,576302,uncivil,574882,"Pavel,    I agree that this statement is incorrect.  Calling this a lie is a completely unjustified personal attack on those who spent quite a lot of time on writing up documentation in the first place. It's suggesting that this document was written with malicious intent and the purpose of deceiving someone. Care to explain why you are assuming this to be the case?   Sure. That still does not justify the changelog"" you provided.   It's interesting that quite some people were actually happy about that document. Sorry, that we weren't able to live up to your high standards.   What is the advertisement part again?   It's a document targeted at system administrators and it definitely should not be buried somewhere in Documentation/x86. As there are more documents being worked on for the other issues, I have a patch ready which moves that stuff into a separate hardware vulnerabilities folder in the admin-guide.  FWIW, to the best of my knowledge the documentation about writing changelogs is neither incorrect nor is it optional to adhere to it.   The 'Affected processors' section right below this is very clear about this being an Intel only issue (for now). So what exactly is the point of this change?   On x86-32? That's incorrect, because there are a lot of x86-32 systems which are not affected. Also it has nothing to do with the bit-width of the hardware. A 32bit kernel booted on a 64bit capable CPU has the same issue. For further correctness, this needs to mention that !PAE enabled kernels cannot do PTE inversion at all.   The 2G limitation is not a general limitation. The limitation depends on the number of physical address bits supported by the cache (not the number of physical address bits exposed as pins) and is definitely not hardcoded to 2G. Just because your machine emits the 2G number does not make it universally correct. On a system with 36bit physical address space the limit is 32G and on some CPUs that's actually wrong as well, see: override_cache_bits().  Quoting yourself:   Where is the explanation for the 'really big 64bit systems' issue for correctness sake?""",uncivil
498594,590551,uncivil,576302,"So how should it be called? I initially used less strong words, only to get Care to tell what's a lie instead of making bold statements?"" back. Also look at the timing of the thread.   Ok, now can we have that document updated to meet the standards?   Making it very clear from the beginning this is x86-only issue. Yes, you can kind-of figure it out from the next section... except for Intel StrongArm.  Next sentence speaks about ""present bit"" of ""page table entry"". That may be confusing for people familiar with other architectures, which may not have such bit. We should mention this is x86 before using x86-specific terminology.   Ok.   I don't know the detailed limits for each system, what about this?  Terminal Fault  1 Terminal Fault is a hardware vulnerability which allows unprivileged -speculative access to data which is available in the Level 1 Data Cache -when the page table entry controlling the virtual address, which is used -for the access, has the Present bit cleared or other reserved bits set. +L1 Terminal Fault is a hardware vulnerability on most recent Intel x86 +CPUs which allows unprivileged speculative access to data which is +available in the Level 1 Data Cache when the page table entry +controlling the virtual address, which is used for the access, has the +Present bit cleared or other reserved bits set.    Affected processors  Attack scenarios     deterministic and more practical.       The Linux kernel contains a mitigation for this attack vector, PTE -   inversion, which is permanently enabled and has no performance -   impact. The kernel ensures that the address bits of PTEs, which are not -   marked present, never point to cacheable physical memory space. - -   A system with an up to date kernel is protected against attacks from -   malicious user space applications. +   inversion, which has no measurable performance impact in most +   configurations. The kernel ensures that the address bits of PTEs, +   which are not marked present, never point to cacheable physical +   memory space. For mitigation to be effective, physical memory needs +   to be limited in some configurations. + +   Mitigation is present in kernels v4.19 and newer, and in +   recent -stable kernels. PAE needs to be enabled for mitigation to +   work.    2. Malicious guest in a virtual machine  ]",uncivil
498594,770007,uncivil,590551,"Pavel,    You called it a lie from the very beginning or what do you think made me tell you that? Here is what you said:   Nice try.   What is 'the standards'? Your's or is there a general agreement?   It's pretty clear, but yes admittedly we forgot to mention that Intel StrongARM is not affected. That's truly important because its widely deployed in the cloud space and elsewhere.   X86 terminology? Care to check how pte_present() is implemented across the architectures? Most of them use the PRESENT bit naming convention, just a few use VALID. That's truly confusing and truly x86 specific.   It's not about detailed limits for particular systems. It's about the way the limit is determined on certain class of systems. And that can be deduced from the code.  If you want to provide more accurate documentation then you better come up with something which is helpful instead of completely useless blurb like the below:   How is the admin going to figure that out? What kind of systems might be affected by this?   No. The mitigation is available when the kernel provides it. Numbers are irrelevant because that documentation has to be applicable for stable kernels as well. And what is a recent -stable kernel?  Also the PAE part needs to go to a completely different section.",uncivil
511533,512783,uncivil,511533,Remove unusual_cypress.h which is included more than once. ,technical
521470,533953,civil,533830,"Just to clarify to the new Cc'ed list, I'm waiting on one of the Chromium guys to review before I put my mucky paws over it. ",technical
522705,522783,uncivil,522702,"To enable the use of dlock-list in an interrupt handler, a new irqsafe mode can now be specified at dlock-list allocation time as an additional argument to alloc_dlock_list_heads(). With that mode specified, the spin_lock_irqsave/spin_unlock_irqrestore pair will be used instead of the regular lock and unlock calls. There is a slight chance that the list may become empty just  	 * before the lock is acquired. So an additional check is --",technical
539613,546296,civil,539614,"Three new tests added: 1. Send get random cmd, read header in 1st read, read the rest in second    read - expect success 2. Send get random cmd, read only part of the response, send another    get random command, read the response - expect success 3. Send get random cmd followed by another get random cmd, without    reading the first response - expect the second cmd to fail with -EBUSY ",technical
539613,546377,uncivil,546296,You are missing a cover letter from this patch set. Please have it in v2. Also use tag instead of having two tags in the short summaries. Now they look a bit weird.  ,civil
541450,541515,uncivil,541509,"Copy_from_user should be safe to copy an arbitrary amount, the only restriction is that optlen can't exceed the size of the buffer receiving the data in the kernel.  From that standpoint your patch is safe.  However,  that exposes the problem of checking any tail data on the userspace buffer.  That is to say, if you want to ensure that any extra data that gets sent from userspace isn't 'set', you would have to copy that extra data in consumable chunks and check them individually, and that screams DOS to me (i.e. imagine a user passing in a 4GB buffer, and having to wait for the kernel to copy each X sized chunk, looking for non-zero values).",technical
541450,541516,uncivil,541515,"I'm not sure that forcing a library on users is a good reason to break UAPI.   The patch is going into the latest, but can also be backported on future stables. I don't think not fixing it because it's not fixed yet"" is a good reason to keep things the way they are. But maybe that's just me. Given that the structure has already been extended several times, there is pretty much nothing to keep this from happening again and again.   --""",uncivil
541450,542126,uncivil,541519,"And I was just reminded about huge pages. But still, my point of finding a compromise still stands.",technical
541450,543076,uncivil,542900,More confusing than I intended...  With the current kernel and headers a 'new program' (one that needs the new options) will fail to run on an old kernel - which is good. However a recompilation of an 'old program' (that doesn't use the new options) will also fail to run on an old kernel - which is bad.  Changing the kernel to ignore extra events flags breaks the 'new' program.  Versioning the structure now (even though it should have been done earlier) won't change the behaviour of existing binaries.  However a recompilation of an 'old' program would use the 'old' structure and work on old kernels. Attempts to recompile a 'new' program will fail - until the structure name (or some #define to enable the extra fields) is changed.  Breaking compilations is much better than unexpected run-time behaviour. ,technical
541450,544269,uncivil,543076,"I disagree with this, at least as a unilateral statement.  I would assert that an old program, within the constraints of the issue being discussed here, will run perfectly well, when built and run against a new kernel.  At issue is the size of the structure sctp_event_subscribe, and the fact that in several instances over the last few years, its been extended to be larger and encompass more events to subscribe to.  Nominally an application will use this structure (roughly) as follows:  Assume this code will be built and run against kernel versions A and B, in which: A) has a struct sctp_event_subscribe with a size of 9 bytes B) has a struct sctp_event_subscribe with a size of 10 bytes (due to the added field sctp_sender_dry_event)  That gives us 4 cases to handle  1) Application build against kernel A and run on kernel A.  This works fine, the sizes of the struct in question will always match  2) Application is built against kernel A and run on kernel B.  In this case, everything will work because the application passes a buffer of size 9, and the kernel accepts it, because it allows for buffers to be shorter than the current struct sctp_event_subscribe size. The kernel simply operates on the options available in the buffer.  The application is none the wiser, because it has no knowledge of the new option, nor should it because it was built against kernel A, that never offered that option  3) Application is built against kernel B and run on kernel B.  This works fine for the same reason as (1).  4) Application is built against kernel B and run on kernel A.  This will break because the application is passing a buffer that is larger than what the kernel expects, and rightly so.   The application is passing in a buffer that is incompatible with what the running kernel expects.  We could look into ways in which to detect the cases in which this might be 'ok', but I don't see why we should bother, because at some point its still an error to pass in an incompatible buffer.  In my mind this is no different than trying to run a program that allocates hugepages on a kernel that doesn't support hugepages (just to make up an example).  Applications built against newer kernel can't expect all the features/semantics/etc to be identical to older kernels.  It shouldn't.  Assuming you have a program built against headers from kernel B (above), if you set a field in the structure that only exists in kernel B, and try to run it on kernel A, you will get an EINVAL return, which is correct behavior because you are attempting to deliver information to the kernel that kernel A (the running kernel) doesn't know about.  That's correct behavior.  I won't disagree about the niceness of versioning, but that ship has sailed.  To be clear,  this is situation (1) above, and yeah, running on the kernel you built your application against should always work from a compatibility standpoint.   Yes, but this is always the case for structures that change.  If you have an application built against kernel (B), and uses structure fields that only exist in that version of the kernel (and not earlier) will fail to compile when built against kernel (A) headers, and that's expected.  This happens with any kernel api that exists in a newer kernel but not an older kernel.  Any time you make a system call to the kernel, you have to be prepared to handle the resulting error condition, that's not unexpected.  To assume that a system call will always work is bad programming practice.  ",uncivil
546823,547238,uncivil,547224,Basic C programming course:   The prototype must be available before the declaration of the global  function.  Oh well....,technical
571417,571702,civil,571698,Agreed... it seems fishy at least.  --  Sent from my Android device with K-9 Mail. Please excuse my brevity.,technical
72369,470502,uncivil,470438,"What do you mean by 1st and 2nd level?     Pretty much. (3) is true in the sense that memory is first allocated from hostmem_resource (which is non-dom0 RAM).    Not anymore, as far as that particular commit is concerned, but that's because of 03a551734 (x86/PCI: Move and shrink AMD 64-bit window to avoid conflict"") which was introduced after balloon patch. IIRC there were some issues with unrelated to balloon.    The concern is that in principle nothing prevents someone else to do exact same thing fa564ad96366 did, which is grab something from right above end of RAM as the kernel sees it. And that can be done at any point.   ",technical
