quotation,code
"Hi,Thanks for the details.Initially i was sceptical of rst & once instead of hitting the fly, hit ""make htmldocs"" on the keyboard :), and the opinion about it was changed. It was easy to navigate through various docs & the realized that various topics (& many) were present (yes, it was there earlier also, but had to dive inside Documentation & search, while viewing the top level index.html made them standout). It was like earlier you had to go after docs, but now it was docs coming after you, that is my opinion.Later while fighting with memory-barriers.txt, felt that it might be good for it as well as to be in that company. And the readability as a text is not hurt as well.It was thought that rst conversion could be done quickly, but sincethis was my first attempt with rst, had to put some effort to get anot so bad output, even if this patch dies, i am happy to have learn trst conversion to some extent. When one of the author of the original document objected, i felt it is better to back off. But if there is a consensus, i will proceed. ",non-technical
"As per the in-kernel documentation, I am now allowed to make fun of you. You are trying to ""out smart"" the kernel by getting rid of a warning message that was explicitly put there for you to do something.  To think that by just providing an ""empty"" function you are somehow fulfilling the API requirement is quite bold, don't you think? This has to be fixed.  I didn't put that warning in there for no good reason.  Please go read the documentation again...",non-technical
Please do not repost with such a small changes. It is much more important to sort out the big picture first and only then deal with minor implementation details. The more versions you post the more fragmented and messy the discussion will become. You will have to be patient because this is a rather big change and it will take  quite  some time to get sorted. Thanks!,non-technical
"Pulled, and then immediately unpulled again. The code causes new compiler warnings, and the warnings are valid. If people don't care enough about their code to even check thewarnings, I'm not going to waste one second pulling the resulting garbage. It's that simple.  ",non-technical
Could you please just merge the obvious fix from Arnd instead?[ it was posted two weeks ago and ACKed by me.,non-technical
The init function is making sure cal type is one or another. Can you fix it correctly by replacing the 'switch' by a 'if' instead of adding dead branches to please gcc? ,non-technical
"Did you actually test this?  The usual reason for wanting m/u delay isthat the timing must be exact.  The driver is filled with mdelay()s forthis reason.  The one you've picked on is in the init path so it won't affect the runtime in any way.  I also don't think we have the hr timer machinery for usleep range() to work properly on parisc, so I don't think the replacement works. ",non-technical
"This doesn't have to be on separate lines; as written, it just causes confusion. Good find, but your patch is corrupted to the point where any attenpt to fix it up on my side failed. Please resend without corruption, and please provide a Fixes: line. Thanks, Guenter",non-technical
"Sorry, but this is a hack to *try* to make multi-slot work and this isn't sufficient. There were good reasons to why the earlier non-working multi slot support was removed from dw mmc. Let me elaborate a bit for your understanding. The core uses a hostlock (mmc claim|release host()) to serialize operations and commands, as to confirm to the SD/SDIO/(e) MMC specs. The above changes gives noguarantees for this. To make that work, we would need a ""mmc bus lock"" to be managed by the core. However, inventing a ""mmc bus lock"" would lead to other problemsrelated to I/O scheduling for upper layers - it simply breaks. Forexample, I/O requests for one card/slot can then starve I/O requests reaching another card/slot. ",non-technical
"What actually took so long?  Could you analyze further instead of blindly putting the flag? thanks,Takashi",non-technical
"Please enlighten me: how do you think this could be exploited? When an application calls VIDIOC ENUM FMT from a /dev/video0 device, it will just enumerate a hardware functionality, with is constantfor a given hard ware piece.The way it works is that userspace do something like: in order to read an entire const table.Usually, it doesn't require any special privilege to call this ioctl, but, even if someone changes its permission to 0x400, a simple lsusboutput is enough to know what hardware model is there. A lsmodor cat /proc/modules) also tells that the tm6000 module was loaded,with is a very good hint that the tm6000 is there or was there in thepast.In the specific case of tm6000, all hardware supports exactly thesame formats, as this is usually defined per-driver. So, a quick lookat the driver is enough to know exactly what the ioctl would answer. Also, the net is full of other resources that would allow anyone to get the supported formats for a piece of hardware. Even assuming that the OS doesn't have lsusb, that /proc is not mounted, that /dev/video0 require special permissions, that the potential attacker doesn't have physical access to the equipment (inorder to see if an USB board is plugged), etc... What possible harmhe could do by identifying a hardware feature?Similar notes for the other patches to drivers/media in thisseries: let's not just start adding bloatware where not needed.Please notice that I'm fine if you want to submit potential Spectre variant 1 fixups, but if you're willing to do so, please provide an explanation about the potential threat scenarios that you're identifying at the code. Dan, It probably makes sense to have somewhere at smatch a place where we could explicitly mark the false-positives, in order to avoiduse to receive patches that would just add an extra delay where it is not needed.",non-technical
"Hi Dmitry - thanks for the review!okok - will have this in oops, did not mean to submit that it was for original debugging and not needed - will remove Yes, that makes sense. I'll propose something like the following in v2: right - thanks! I am using request threaded irq with thread fn with thread fn (vs handler).Do you mean why use a work procedure? I guess I don't need that andcan call input report key directly from the irq. ok can you point me to an example dts/driver? ",non-technical
"I suppose these sort of patches are as much a PITA for the sender than for the receivers. I hesitated between a single patch, a series or separated patches. In a sense, the single patch would have been the easier for both sides but I guessed it would not have been very well welcomed. Since for a series, you're supposed to CC the whole series to everyone involved, it would have been, or at least at thought so, maximally noisy for nogood reasons. Finally, as all of these patches are totally independent, I thought it would be the best to send them as separated patches, each drivers maintainers being then free to accept, reject or ignore the patch(es) concerning him/her. It seems it was a bad guess, and yes, I see the point of having a series for this. I'll remember all this for the next time (if next time there is, of course, I was already quite hesitant to spend time to prepareand send patches for these issues with enum/integer mix-up). Sorry for the annoyance,-- Luc",non-technical
,
"Either it does exist, or it doesn't. If it exists, it needs to be fixed.  If it doesn't exist, nothing needs to be done. Which is the case?",non-technical
,
It looks like you are not actually sure what you are doing then.,non-technical
"I do share your view Mike! This all looks so hackish and ad-hoc that I would be tempted to give it an outright nack, but let's here more about why do we need this fiddling at all. I've asked in other email so I guess I will get an answer therebut let me just emphasize again that I absolutely detest a possibilityto put hugetlb pages into the memcg mix. They just do not belong there.Try to look at previous discussions why it has been decided to have a separate hugetlb pages at all. I am also quite confused why you keep distinguishing surplus hugetlbpages from regular preallocated ones. Being a surplus page is an implementation detail that we use for an internal accounting rather than something to exhibit to the userspace even more than we do currently. Just look at what would/ should when you need to adjust accounting - e.g.due to the pool resize. Are you going to uncharge those surplus pages from memcg to reflect their persistence?",non-technical
"Where did this come from? XFS doesn't use the underlying block devaddress space, so this does nothing at all and should not be here.So to return errors correctly, xfs fs sync fs() needs to capture errors from the log force (i.e. metadata errors such as filesystem shutdowns, journal IO errors, etc), then check for pending data IOerrors",non-technical
The SPDX header is explicitly here to remove the license text and create a tag that is in a indirect reference to the license text in LICENSES. It's not going away. I never said we were perfect reviewers. Feel free to help in the process. ,non-technical
But you did it again....Your email client should not be forcing you to top post. So please don't.,non-technical
I took a closer look at this and it's not necessary. (Note: I do the majority of my testing in a looped-back setup). What you didn't notice is that split remote() separates the colon whether there is a host or not. It's not passed to ssh or cat (or whatever) directly. So the change you propose will actually break the how it was designed.,non-technical
There are no unexpected results. Making a non-fatal error fatal doesn't serve a useful purpose. ,non-technical
"What is this crazy union for?  Why are you messing around with ""raw"" kobject attributes?  This is a device, you should never have to mess with sysfs calls or kobject calls or structures directly.  If you do, that's a huge hint something is wrong here. You aren't ""adding"" any attributes here, you are only setting them up (in an odd way, see below...) That's an oddly-hard-coded array size for no good reason : (This works?  You normally have to manually initialize a dynamic attribute.  Why are you doing it this way and not using an attribute group? Why are you using a custom device class for a single device? you need to document the heck out of this in the changelog to help explain all of these odd design decisions.",non-technical
"No, at this point it requires both I2C and OF. I may add platform data to support an older non-device-tree family of boards but it still would require I2C. I will remove the || COMPILE TEST Thanks for catching that. ",non-technical
"(and replying to your other comments as well)...This is an RFC series, it's not meant for you to take at this point,it's about discussing the overall approach to exposing BMC random ""tunables"" as explained in patch 0 of the series. Yes the individual patches aren't yet at the level of polish for aformal submission, we (naively ?) thought that's what the whole RFC tag is about :-) ",non-technical
"Well, it adds documentation :-) You can just read the patch which is... the documentation :) Yes, you did that's fine. Thanks. ",non-technical
"Oh come on, putting a basic ""here is what this patch does"" comment should be part of every patch, otherwise what is there to comment on if we don't know what is going on in the patch itself? Anyway, I provided a bunch of feedback to the ""real"" patch in this series...",non-technical
"Yeah, not going to happen. You grow that structure from 64 bytes to 96bytes and with that grow the static footprint of the kernel by 512k (in the very best case) possibly again breaking things like sparc (which have a strict limit on the kernel image size). And all that for data that I've never needed and never even considered useful when looking at lock dep output.",non-technical
"I  confirm that in case of x86 64, the bss size is increased by ~1M [1] with standard v4.18-rc4 x86 64 defconfig + CONFIG LOCKDEP. For sparc there seems to be a dedicated CONFIG LOCKDEP SMALL, which seems to downsize the lockdep implementation anyway. It's likely because you infer about certain aspects which are not clearly stated in the deadlock report. As example, the original report doesn't say that the process which holds 'cpu hotplug lock.rw sem' is different to the process which holds the other locks. On thecontrary, it tells the user that all the locks are being held by thesame task, which seems to be wrong.You likely also infer about the order of consuming the locks based onthe contents of the stack dump associated to each lock. Without doing some mental diffs between the backtraces, it's not possible to see thechronological order of consuming the locks. Actually this only works for backtraces with common history, i.e. there is no clue what is the time/point of acquiring 'cpu hotplug lock.rw sem' relative to the otherlocks. The patch mostly shares my personal experience of trying to make sense of lockdep output. It's OK if it doesn't reach mainline. I still hope that I can get some feedback from community regarding the actual cpu freq-related issue pointed out in the splat. I can also reproduce it on v4.14, so it appears to be in the kernel for quite some time.Thank you in advance. BSS size increase after applying the patch",non-technical
"These calling conventions are rather suboptimal.  First of all, none of the callbacks will ever get called directly.	* there are only 4 callers.  3 of them (all in fs.h) are of the form return ....;  The fourth is which itself is an ->actor() callback.So all these ""return -E..."" in the instances are completely pointless; we should just turn filldir t into pointer-to-function-returning-booland get rid of that boilerplate, rather than adding more to it. Furthermore, who the hell cares which callback has stepped into it?"" The first time it happened from getdents(2) in a 32bit process and that's all you'll ever get out of me"" seems to be less than helpful...And frankly, I would prefer making that thing return -EUCLEAN or 0.  Quite possibly - inlining it as well...",non-technical
Thanks for the reviewThe problem we have here is there is a potential to control 3  different LED string but only 2 sinks.  So control bank A can control 2 LED strings and control bank b can control 1 LED string.These values represent device level control and configuration of the LED strings to a specific control bank.I racked my brain trying to figure out how to configure the control banks and associated LED strings.These values are for the device configuration itself and the reg below indicates which control bank the LEDnode is assigned to. Don't see how you could compute this.  There is no easy way to give indication to the driver which LEDnode belongs to which control bank.  The control-bank-cfg is a device level property and the reg under the child is a LED string level property denoting the Class node to control bank mapping. Furthermore there are 2 device configurations that can be configured to only use 1 bank for all 3 LED strings. This will be answered in your comments in the code. This I can fix it should be a value between 1 and 6.,non-technical
"It is better do add some complexity to the driver than to the user configurable settings like DT. Besides - you will only need tocheck if given led-source is already taken by another node. Some description will be needed for sure, but I don't expect it to be overwhelmingly lengthy.Your control-bank-cfg seemed like having much room for improvement,and it would for sure raise questions on why it was implemented that way. Documenting all available combinations of the configuration is seldom the best solution. It often obscures the issue. In your bindings device configuration is scattered among global control-bank-cfg property and child node's reg property.In my proposal each child node contains all the needed configuration, also in the form of two properties - led-sources and reg. IMHO having all the LED class device related configuration in one place simplifies the analysis.",non-technical
"This patch was corrupted by your email client, for example it turned TAB characters into sequences of spaces. Please fix this, email a test patch to yourself, and do not resend the patch to this mailing list until you can successfully extract and cleanly apply the test patch you email to yourself. Thank you.",non-technical
"Again I'll ask: what is the performance when the log is made large enough that your benchmark is *not hammering the slow path*? i.e. does running instead of using thedefault tiny log on your tiny test file system make the problemgo away? Without that information, we have no idea what the slowpath impact on peformance actually is, and whether it is worth persuing optimising slow path behaviour that very, very fewproduction environments see lock contention in....",non-technical
"Thanks for the review! oops - left that in by mistake.It has 16x ADC channels where some can be temperatures and others can be voltage inputs (based on device tree). understood - a much cleaner pattern right - removed yikes - thanks for catching that ok yes, that static arrays are not very forward-thinking and yes my arrays are not consistent. I'll convert to dynamically allocating the channels for v2right - certainly an issue will do will add validation ok Do you mean stuffing a u32 into a u8? will fix will fix will do could also return -EINVAL but not with the args I'm passing in so I'll change it to this.",non-technical
"Ick, this is still messy, just try making this: Yeah, it's over 80 columns, but it looks better and is easier to read,right? Also, all your patches have the whitespace turned from tabs into spaces, making them impossible to be applied even if I wanted to :) ",non-technical
"I don't call this non-intrusive. I'll beg to differ; this isn't anywhere near something to consider merging. Also 'happened' suggests a certain stage of completeness, this again doesn't qualify.There are known scalability problems with the existing cgroup muck; youjust made things a ton worse. The existing cgroup overhead is significant, you also made that many times worse.The cgroup stuff needs cleanups and optimization, not this. That is the whole and only reason you did this; and it doesn't even begin to cover the requirements for it. Not to mention I detest cgroups; for their inherent complixity and the performance costs associated with them.   If  we're going to dosomething for L1TF then I feel it should not depend on cgroups. It is after all, perfectly possible to run a kvm thingy without cgroups. Note that in order to avoid PLE and paravirt spinlocks and paravirttlb-invalidate you have to gang-schedule the  entire  VM, not just SMTsiblings. Now explain to me how you're going to gang-schedule a VM with a goodnumber of vCPU threads (say spanning a number of nodes) and preserving the rest of CFS without it turning into a massive trainwreck? Such things (gang scheduling VMs)  are  possible, but not within the confines of something like CFS, they are also fairly inefficient because, as you do note, you will have to explicitly schedule idle time for idle vCPUs.Things like the Tableau scheduler are what come to mind; but I'm not sure how to integrate that with a general purpose scheduling scheme. You pretty much have to dedicate a set of CPUs to just scheduling VMs with such a scheduler.And that would call for cpuset-v2 integration along with a new scheduling class. And then people will complain again that partitioning a system isn't dynamic enough and we need magic :/(and this too would be tricky to virtualize itself) You gloss over a ton of details here; many of which are non trivial and marked broken in your patches. Unless you have solid suggestions on how to deal with all of them, this is a complete non-starter.The per-cpu IRQ/steal time accounting for example. The task timeline isn't the same on every CPU because of those. You now basically require steal time and IRQ load to match between CPUs.That places very strict requirements and effectively breaks virt invariance. That is, the scheduler now behaves significantly different inside a VM than it does outside of it -- without the guest being gang scheduled itself and having physical pinning to reflect the same topology the coschedule=1 thing should not be exposed in a guest. And that is a major failing IMO. Also; I think you're sharing a cfs rq between CPUs: that is broken, the virtual runtime stuff needs nontrivial modifications for multiple CPUs. And if you do that, I've no idea how you're dealing with SMP affinities.You don't even begin to outline how you preserve smp-nice fairness.IOW it's completely friggin useless for L1TF. Have you actually read your own code? What about that atrocious locking you sprinkle all over the place?'some additional lock contention' doesn't even begin to describe that horror show.Hint: we're not going to increase the lockdep subclasses, and most certainly not for scheduler locking. All in all, I'm not inclined to consider this approach, it complicates an already overly complicated thing (cpu-cgroups) and has a ton of unresolved issues while at the same time it doesn't (and cannot) meet the goal it was made for.",non-technical
"Mm... there is certainly room for interpretation. :) For example, it is still possible to set affinities, to use nice, and to tune all the other existing CFS knobs. That is, if you have tuned the scheduler to your workload or your workload depends on some CFS feature to work efficiently (whether on purpose or not), then running with this patch set should not change the behavior of said workload.This patch set should ""just"" give the user the additional ability to coordinatesche duling decisions across multiple CPUs. At least, that's my goal. If someone doesn't need it, they don't have to use it. Just like task groups.But maybe, people start experimenting with coordinated scheduling decisions --after all, there is a ton of research on what one *could* do, if there was coscheduling. I did look over much of that research. What I didn't like aboutmany of them, is that evaluation is based on a ""prototype"", that -- whilemaking the point that coscheduling might be beneficial for that use case --totally screws over the scheduler for any other use case. Like coscheduling based on deterministic, timed context switches across all CPUs. Bye bye interactivity. That is, what I call intrusive. As mentioned before, existing scheduler features, like preemption, (should) still work as before with this variant of coscheduling, with the same look andfeel.And who knows, maybe someone will come up with a use case that moves coscheduling out of its niche; like the auto-grouping feature promoted the use of task groups.I agree, that this isn't ready to be merged. Still, the current state is good to start a discussion about the involved mechanics.Are you referring to cgroups in general, or task groups (aka. the cpucontroller) specifically? With respect to scalability: many coscheduling use cases don't requiresynchronization across the whole system. With this patch set, only thoseparts that are actually coscheduled are involved in synchronization.So, conceptually, this scales to larger systems from that point of view.If coscheduling of a larger fraction of the system is required, costs increase. So what? It's a trade-off. It may *still* be beneficial for ause case. If it is, it might get adopted. If not, that particular usecase may be considered impractical unless someone comes up with a better implementation of coscheduling.With respect to the need of cleanups and optimizations: I agree, that task groups are a bit messy. For example, here's my current wish listoff the top of my head:a) lazy scheduler operations; for example: when dequeuing a task, don't bother walking up the task group hierarchy to dequeue all the SEs -- do it lazily   when encountering an empty CFS RQ during picking when we hold the lock anyway.b) ability to move CFS RQs between CPUs: someone changed the affinity of   a cpuset? No problem, just attach the run queue with all the tasks elsewhere.   No need to touch each and every task. c) light-weight task groups: don't allocate a runqueue for every CPU in the   system, when it is known that tasks in the task group will only ever run   on at most two CPUs, or so. (And while there is of course a use case for   VMs in this, another class of use cases are auxiliary tasks, see eg, [1-5].)Is this the level of optimizations, you're thinking about? Or do you want to throw away the whole nested CFS RQ experience in the code?It really isn't. But as your mind seems made up, I'm not going to botherto argue.Yes it is. But, for example, you won't have group-based fairness between multiple kvm thingies.Assuming, there is a cgroup-less solution that can prevent simultaneous execution of tasks on a core, when they're not supposed to. How would youtell the scheduler, which tasks these are?You probably don't -- for the same reason, why it is a bad idea to givean endless loop realtime priority. It's just a bad idea. As I said in thetext you quoted: coscheduling comes with its own set of advantages anddisadvantages. Just because you find one example, where it is a bad idea,doesn't make it a bad thing in general.With gang scheduling as defined by Feitelson and Rudolph [6], you'd have to explicitly schedule idle time. With coscheduling as defined by Ousterhout [7],you don't. In this patch set, the scheduling of idle time is ""merely"" a quirk of the implementation. And even with this implementation, there's nothing stopping you from down-sizing the width of the coscheduled set to take outthe idle vCPUs dynamically, cutting down on fragmentation.Hence my ""counter"" suggestion in the form of this patch set: Integratedinto a general purpose scheduler, no need to partition off a part of the system,not tied to just VM use cases.Yes, I do. :) I wanted a summary, not a design document. Maybe I was a bitto eager in condensing the design to just a few paragraphs...Address them one by one. Probably do some of the optimizations you suggestedto just get rid of some of them. It's work in progress. Though, at thisstage I am also really interested in things that are broken, that I am notaware of yet.I'll have to read up some more code to make a qualified statement here.It is not shared per se. There's only one CPU (the leader) making the scheduling decision for that run queue and if another CPU needs to modify the run queue, it works like it does for CPU run queues as well: the other CPU works with theleader's time. There are also no tasks in a run queue when it is responsible for more than one CPU. Assuming, that a run queue is responsible for a core and there are runnable tasks within the task group on said core, then there will one SE enqueued in that runqueue, a so called SD-SE (scheduling domain SE, or synchronizationdomain SE). This SD-SE represents the per CPU runqueues of this core of thistask group. (As opposed to a ""normal"" task group SE (TG-SE), which representsjust one runqueue in a different task group.) Tasks are still only enqueuedin the per CPU runqueues.Works as before (or will work as before): a coscheduled task group has itsown set of per CPU runqueues that hold the tasks of this group (per CPU).The load balancer will work on this subset of runqueues as it does on the""normal"" per CPU runqueues -- smp-nice fairness and all.Do you believe me now, that L1TF is not ""the whole and only reason"" I did this? :DCurrently, there are more code paths than I like, that climb up the se->parent relation to the top. They need to go, if we want to coschedule larger parts ofthe system in a more efficient manner. Hence, parts of my wish list further up.That said, it is not as bad as you make it sound for the following three reasons:a) The amount of CPUs that compete for a lock is currently governed by the   ""cosched max level"" command line argument, making it a conscious decision to   increase the overall overhead. Hence, coscheduling at, e.g., core level   does not have a too serious impact on lock contention.b) The runqueue locks are usually only taken by the leader of said runqueue.   Hence, there is often only one user per lock even at higher levels.   The prominent exception at this stage of the patch set is that enqueue and   dequeue operations walk up the hierarchy up to the ""cosched max level"".   And even then, due to lock chaining, multiple enqueue/dequeue operations   on different CPUs can bubble up the shared part of the hierarchy in parallel.c) The scheduling decision does not cause any lock contention by itself. Each   CPU only accesses run queues, where itself is the leader. Hence, once you   have a relatively stable situation, lock contention is not an issue.That's fine. Due to the overhead of nesting cgroups that you mentioned earlier,that many levels in the runqueue hierarchy are likely to be impracticable anyway. For the future, I imagine a more dynamic variant of task groups/scheduling domains, that can provide all the flexibility one would want without that deepof a nesting. At this stage, it is just a way to experiment with larger systemswithout having to disable lockdep.Of course, if you have a suggestion for a different locking scheme, we candiscuss that as well. The current one, is what I considered most suitableamong some alternatives under the premise I was working: integrate coschedulingin a scheduler as an additional feature (instead of, eg, write a scheduler capable of coscheduling). So, I probably haven't considered all alternatives. Even if you're not inclined -- at this stage, if I may be so bold :) --your feedback is valuable. Thank you for that.Regards JanR eferences (for those that are into that kind of thing)",non-technical
"How can you set a shared variable with no synchronization ? A bool is particularly dangerous here, at least on some arches.",non-technical
"If rtnl trylock() can not grab RTNL,there is no way the current thread can set the  variable without a race, if the word including rtnl needed is shared by other fields in the structure. Your patch adds a subtle possibility of future bugs, even if it runs fine today. Do not pave the way for future bugs, make your code robust, please.",non-technical
"It would be very helpful if you cc all involved people on the cover letter instead of just cc'ing your own pile of email addresses. CC'ed now. This is really not helpful. The cover letter and the change logs should contain a summary of that discussion and a proper justification of the proposed change. Just saying 'sysadmins might want to allow' is not useful at all, it's yet another 'I want a pony' thing. I read through the previous thread and there was a clear request to involves security people into this. Especially those who are deeply involved with hardware side channels. I don't see anyone Cc'ed on the whole series. For the record, I'm not buying the handwavy 'more noise' argument atall. It wants a proper analysis and we need to come up with criteria which PMUs can be exposed at all. All of this want's a proper documentation clearly explaining the risks andscope of these knobs per PMU. Just throwing magic knobs at sys admins and then saying 'its their problem to figure it out' is not acceptable.",non-technical
"Hi,I accept it was by bad to miss adding Cc's on the cover letter, but my own email addresses hopefully should not bother you. It is simply aquestion of what I have in .gitconfig vs what I forgot to do manually. Okay, for the next round I will expand the cover letter with at leastone concrete example on how it is usable and summarize the discussion a bit.Who would you recommend I add? Because I really don't know..Presumably you see adding fine grained control as diminishing the overall security rather than raising it? Could you explain why? Because incompetent sysadmin will turn it off for some PMU, while without havingthe fine-grained control they wouldn't turn it off globally?This feature was requested by the exact opposite concern, that in order to access the i915 PMU, one has to compromise the security of the entiresystem by allowing access to *all* PMU's. Making this ability fine-grained sounds like a logical solution for solving this weakening of security controls. Concrete example was that on video transcoding farms users want to monitor the utilization of GPU engines (like CPU cores) and they can do that via the i915 PMU. But for that to work today they have to dial downthe global perf event paranoid setting. Obvious improvement was to allowthem to only dial down the i915.perf event paranoid setting. As such, for this specific use case at least, the security is increased. Regards,Tvrtko",non-technical
"The keyword in the above sentence is 'just'. You can add as many of yours as you want as long as everybody else is cc'ed. Sure, and because you don't know you didn't bother to ask around and ignored the review request. I already added Kees and Jann. Please look for the SECCOMP folks inMAINTAINERS. I did not say at all that this might be diminishing security. And the argumentation with 'incompetent sysadmins' is just the wrong attitude. What I was asking for is proper documentation and this proper documentation is meant for  competent  sysadmins.That documentation has to clearly describe what kind of information is accessible and what potential side effects security wise this mighthave. You cannot expect that even competent sysadmins know offhand whatwhich PMU might expose. And telling them 'Use Google' is just not the right thing to do. If you can't explain and document it, then providing the knob is justfulfilling somebodys 'I want a pony' request. Sure, and this wants to be documented in the cover letter and the changelogs.But this does also require a proper analysis and documentation why it is not a security risk to expose the i915 PMU or what potential securityissues this can create, so that the competent sysadmin can make a judgement.And the same is required for all other PMUs which can be enabled in the same way for unprivileged access. And we might as well come to the conclusion via analysis that for some PMUs unpriviledged access is just nota good idea and exclude them. I surely know a few which qualify for exclusion, so the right approach is to provide this knob only when the risk is analyzed and documented and the PMU has been flagged as candidate for unpriviledged exposure. I.e. opt in and not opt out.",non-technical
"Sure, but you also used the word ""pile"" and I would argue that made therest of your sentence, after and including ""instead"", sound like it notonly bothers you I forgot to Cc people on the cover letter, but it alsobothers you I included a ""pile"" of my own addresses. If that wasn't yourintention in the slightest then I apologise for misreading it.No, not because of that. You are assuming my actions and motivations and constructing a story.""did not bother"" = negative connotations""ignored"" = negative connotations Note instead the time lapse between this and previous posting of theseries, and if you want to assume something, assume things can getmissed and forgotten without intent or malice.Thanks! Wrong attitude what? I was trying to guess your reasoning (cues in""presumably"" and a lot of question marks) since it wasn't clear to mewhy is your position what it is.I did not mention Google. Well it's not a pony, it is mechanism to avoid having to turn off allsecurity. We can hopefully discuss it without ponies.I am happy to work on the mechanics of achieving this once the securityguys and all PMU owners get involved. Even though I am not convinced thebar to allow fine-grained control should be evaluating all possiblePMUs*, but if the security folks agree that is the case it is fine by me.Regards, Tvrtko*) The part of my reply you did not quote explains how the fine-grained control improves security in existing deployments. The documentation I added refers to the existing perf event paranoid documentation for explanation of security concerns involved. Which is not much in itself. But essentially we both have a PMU and a knob already. I don't see why adding the same knob per-PMU needs much more stringent criteria to be accepted. But as said, that's for security people to decide.",non-technical
"Guessing my reasonings has nothing to do with you mentioning incompentent sysadmins.I did not say that you mentioned google. But what is a sysadmin supposed to do when there is no documentation aside of using google? And not having documentation is basically the same thing as telling them to use google.If you want to make a pettifogger contest out of this discussion, then we can stop right here. I explained it technically why just adding a knobwithout further explanation and analysis is not acceptable. Making the knob opt in per PMU does not need all PMU owners to beinvolved. It allows to add the opt in flag on a case by case basis. The fact, that the existing knob is poorly documented does make an excuse for adding more knobs without documentation. Quite the contrary, if we notice that the existing knob lacks proper documentation, then we should fix that first.",non-technical
"Sorry for being dense. What tree is this against? I can't find mention of amdcz in Linus's tree nor linux-next. Where does get used where isn't defined? (i.e. why is the #ifdef needed here?) Otherwise, sure, sounds good. :)",non-technical
"Ah only if google could simply answer all our questions! It's not like there is or isn't a security risk and that you can say that it is or it isn't in a global way.Essentially these are channels of information. The channels always exist in form of timing variances for any shared resource (like shared caches or shared memory/IO/interconnect bandwidth) that can be measured. Perfmon counters make the channels generally less noisy, but they do not cause them.To really close them completely you would need to avoid sharing anything, or not allowing to measure time, neither of which is practical short of an air gap.There are reasonable assesments you can make either way and the answers will be different based on your requirements. There isn't a single answer that works for everyone.There are cases where it isn't a problem at all.If you don't have multiple users on the system your tolerance should be extremely high. For users who have multiple users there can be different tradeoffs. So there isn't a single answer, and that is why it is important that this if configurable.",non-technical
"I said clearly that I'm not opposed against making it configurable. But because there is no single answer, it's even more important to have proper documentation. And that's all I'm asking for aside of making it opt-in instead of a wholesale expose everything approach. ",non-technical
"Even though the return type of ndo start xmit is netdev tx t, negative error codes arestill allowed I believe. Look, reviewing these are pretty stressful for me, because you aren't documenting yourchanges and in many cases the transformations look incorrect. I'm tossing the rest of your changes in this area for now, sorry. Please double check your work and resubmit this at some time in the not-too-near future. Thank you.",non-technical
"The way I see it, it is pretty well marked up as is. So, this paragraph is not describing the change.What is not ""proper"" about the existing comment? Yes yes, I *know* that GCC is not very intelligent about it and requires hand-holding, bu tblaming the existing comment for not *properly* marking an intentional fall through is ... rich.Adding some more context here. Considering the above added context, I have to say that this mindlesschange is not an improvement, as you have just destroyed the continued sentence from the previous comment. You must have noticed that this was the end of a continued sentence, as you even quoted it in the commit message. The big question is why you did not stop to think and consider the context? Yes, I'm annoyed by mindless changes. Especially mindless changes aimed at improving readability while in fact making things less readable.TL;DR, if you are desperate to fix ""the problem"" with this fall through comment, please do so in a way that preserves overall readability. And it would be nice to not blame the existing code for brain damage in GCC and various other static analyzers. ",non-technical
"I still object. It would have been so damn easy and it does not take a wholelot of imagination to quiet down GCC while keeping the comments readable. Just move the ""and"" to the previous comment, like this.IO VAL FRACTIONAL",non-technical
"Which CPU architecture?  Most important architectures appear to define  HAVE ARCH MEMCMP.What the heck does   visible do?This is going to do bad things if the incoming addresses aren't suitably aligned.Certainly, byte-at-a-time is a pretty lame implementation when the addresses are suitably aligned.  A fallback to the lame version whenthere is misalignment will be simple to do.  And presumably there will be decent benefits to whoever is actually using this code.  But I'm wondering who is actually using this code!",non-technical
"Hi Boris The major feature close to USB is this one and it can be found in others protocols (standardization process).Just to close this topic I3C vs USB, IMO it's wrong to pass the message that the I3C is closer to USB than I2C even more because I3C support theI2C on the fly. Sorry, with the proliferation of sensors I cannot see a multi mastersensor network based on USB. Yes, we already talked about secondary master support. I would bet to do something like in i2c, we don't need the same level of complexity found in USB.I agree with the controller folder but not with prefix. Please check what is already in the kernel. In this case and taking what is already in the kernel it will bedrivers/i3c/{master, slave, dwc, other with the same architecture as dwc}.I miss to mention PCI but since the beginning refer the slave and the common part. Splitting the driver is something that soon or later I will have to do.If you prefer later I'm ok with that.I think this discussion is starting to be counterproductive with arguing of both parts. Unfortunately I don't see anyone given their inputs too.To be clear, the subsystem is nice and I working with daily. As I said this is something that I dealing now and I'm telling what I think that is not correct.",non-technical
"I think you didn't read my reply carefully. I'm not saying I3C == USB, I'm just saying that the way you interact with an I3C from a SW PoV isnot at all the same as you would do for an I2C device. Do you deny that? Looks like there's a misunderstanding here. The question is not whether I3C will replace I2C or USB, of course it's meant to overcome the limitations of I2C. I'm just pointing out that, if we have to expose I3C devices, we should look at what other discoverable buses do (PCI,USB, ...), not what I2C does.There's a difference between a secondary master that waits for its time to become the currrent master, and a secondary master that provides I3C device features when it's acting as a slave (sensor, GPIOcontroller, ...). So far we focused on supporting the former. If there's a need for the latter, then we should start thinking about the slave framework...Can you detail a bit more what you have in mind? I don't think we can do like I2C, simply because we need to expose a valid DCR +manuf-ID/PID so that other masters can bind the device to the appropriate driver on their side. Plus, if we're about to expose generic profiles, we likely don't want each I3C slave controller driver to do that on its own.If we mix everything in the same subdir, I'd like to have an easy way to quickly identify those that are slave controllers and those that are master controllers. For the dual-role thing, maybe we can consider them as master (ones with advances slave features). Would you be okay with this..., so that you can have all designware drivers (for both slave and masterblocks) in the same dir? For those that are placed directly under this...(because they only have one .c file), I'd like to keep a standard prefix.And again, I'm questioning the necessity of per-IP directories at theroot level. I'm not against per-IP directories, as long as they are classified like other HW blocks...No it's not vain, it's how we do discuss things in the community. I'm not saying I'm always right, but I need to understand the problems you're trying to solve to take a decision, and I don't think you initially gave all the details I needed to understand your PoV. That's a bit clearer now, even if I still disagree on a few aspects.They will come. Come on! All I've seen so far are complaints on tiny details, it definitely doesn't prevent you from adding new features. ",non-technical
"If you want. Actually that's the most interesting part for me:  discussing how we want to support I3C slave controllers or mixedmaster/slave controllers. All the driver split we're talking abouthere is just bikeshedding. Ok.I don't see why. If the driver is simple enough to fit in one file,there's no reason to create a new subdir. You think your DW IP is so complex and configurable that it requires several source files, fine,but please don't force others to do the same.Yes. You mean, inside a sub-folder? It depends what you do with those source files. If they are to be exposed directly as modules, then they should be prefixed. On the other hand, if you create a single module out of several source files, source files don't need to be prefixed, as long as the resulting module as a proper prefix.I'm not saying the discussion is useless, just that it's happening waytoo early compared to the other things we should work on. If you were adding support for slaves, and were doing this split as part of this patch series explaining that part of the code between slave and master can be shared, then we wouldn't have this debate. But right now, you'retelling me that we need to split the DW driver to prepare for features that have not even been discussed/proposed. That's what I'm complaining about.",non-technical
So I strongly disagree with this. Anybody that has trouble with 0/1 vsfalse/true needs to stay the heck away from C.I would suggest we delete that stupid coccinelle scripts that generates these pointless warns.,non-technical
Can you possibly send the entire series again and CC all patches to linux-acpi and fix the kbuild warnings if the are relevant for that matter? Thanks!,non-technical
Not to mention that WARN is gramatically incorrect. We're not assigning 'bool' to 0/1 but the other way around. What crap..,non-technical
"Then those tools are broken per the C spec.The C language spec, specifies  Bool as an integer type wide enough to at least store 0 and 1.IOW, 0 and 1 are perfectly valid value to assign to a  Bool.And fundamentally that has to be so. That's how computers work. 0 is false, 1 is true.The kernel is not the place to try and abstract such stuff, C is our portable assembler. We muck with hardware, we'd better know how the heck it works.",non-technical
"Note that this patch does *not* remove the nasty trap caused by the garbage in question - struct file can be freed before we even return from->unlocked ioctl().  Could you describe in details the desired behaviourof this interface? How about grabbing the references to all victims (*before* screwing with this), sticking them into a structure with embedded callback on it, the callback doing those fput()? The callback would trigger before the return to userland, so observable timing of the final close wouldn't be changed.  And it would avoid the kludges like this.Of course, the proper fix would require TARDIS and set of instruments for treating severe case of retrocranial inversion, so that this ""ABI"" would've never existed, but...",non-technical
What's advertisement there? Huch? Care to tell what's a lie instead of making bold statements?,non-technical
"""No problem here, no performance issues, nothing to be seen unless youare running VM."" Take a care to look at the patch I submitted? Lie: A system with an up to date kernel is protected against attacks from # malicious user space applications.3GB system running 32bit kernel is not protected. Same is true for for really big 64 bit systems.If I do what he suggests, this becomes untrue. The Linux kernel contains a mitigation for this attack vector, PTE# inversion, which is permanently enabled and has no performance# impact.Limiting memory to 2GB  is  going to have severe perfomance impact. Ok, I guess L1TF was a lot of fun, and there was not time for a good documentation.There's admin guide that is written as an advertisment, and unfortunately is slightly ""inaccurate"" at places (to the point of lying).Plus, I believe it should go to x86/ directory, as this is really Intel issue, and not anything ARM (or RISC-V) people need to know.",non-technical
"I agree that this statement is incorrect. Calling this a lie is a completly unjustified personal attack on those who spent quite a lot of time on writing up documentation in the first place. It's suggesting that this document was written with malicious intent  and the purpose of deceiving someone. Care to explain why you are assuming this to be the case? Sure. That still does not justify the ""changelog"" you provided.It's interesting that quite some people were actually happy about that document. Sorry, that we weren't able to live up to your high standards.What is the advertisement part again? It's a document targeted at system administrators and it definitely should not be buried somewhere in Documentation/x86. As there are more documents being worked on for the other issues, I have a patch ready which moves that stuff into a separate hardware vulnerabilites folder in the admin-guide.FWIW, to the best of my knowledge the documentation about writing changelogs is neither incorrect nor is it optional to adhere to it.The 'Affected processors' section right below this is very clear about this being an Intel only issue (for now). So what exactly is the point of this change? On x86-32? That's incorrect, because there are a lot of x86-32 systems which are not affected. Also it has nothing to do with the bit-width of the hardware. A 32bit kernel booted on a 64bit capable CPU has the same issue. For further correctness, this needs to mention that !PAE enabled kernels cannot do PTE inversion at all.The 2G limitation is not a general limitation. The limitation depends on the number of physical address bits supported by the cache (not the number of physical addresss bits exposed as pins) and is definitely not hardcoded to 2G. Just because your machine emits the 2G number does not make it universally correct. On a system with 36bit physical address space the limit is 32G and on some CPUs that's actually wrong as well, see this. Quoting yourself: Where is the explanation for the 'really big 64bit systems' issue for correctness sake? ",non-technical
"So how should it be called? I initally used less strong words, only to get ""Care to tell what's a lie instead of making bold statements?"" back. Also look at the timing of the thread.Ok, now can we have that document updated to meet the standards?Making it very clear from the begining this is x86-only issue. Yes, you can kind-of figure it out from the next section... except for Intel StrongArm.Next sentence speaks about ""present bit"" of ""page table entry"". That may be confusing for people familiar with other architectures, which may not have such bit. We should mention this is x86 before usingx86-specific terminology.Ok.I don't know the detailed limits for each system; what about this? ",non-technical
"You called it a lie from the very beginning or what do you think made me tell you that? Here is what you said: Nice try.What is 'the standards'? Your's or is there a general agreement?It's pretty clear, but yes admittedly we forgot to mention that Intel StrongARM is not affected. That's truly important because its widely deployed in the cloud space and elsewhere. X86 terminology? Care to check how pte present() is implemented across the architectures? Most of them use the PRESENT bit naming convention, just afew use VALID. That's truly confusing and truly x86 specific.It's not about detailed limits for particular systems. It's about the way the limit is determined on certain class of systems. And that can be deduced from the code.If you want to provide more accurate documentation then you better come upwith something which is helpful instead of completely useless blurb likethe below: How is the admin going to figure that out? What kind of systems might be affected by this? No. The mitigation is available when the kernel provides it. Numbers are irrelevant because that documentation has to be applicable for stable kernels as well. And what is a recent - stable kernel?Also the PAE part needs to go to a completely different section.",non-technical
"Hi! Actually, I still call it a lie. Document clearly says that bug is fixed in non-virtualized cases, when in fact it depends on PAE and limited memory.At this point I want you to fix it yourself. Lying about security bugs being fixed when they are not is not cool. I tried to be helpful and submit a patch, but I don't feel like you are cooperating on getting the patch applied.",non-technical
"Again, no.",non-technical
"Can you add a commit message explaining why you add a specific def config for this board. FYI, previously, the same def config was used for boards.You will also need to resync with the last master branch regarding defconfig content.",non-technical
"I would drop this patch for being too ugly and if nothing else, for lack of users (epoll will no longer need dlock). ",non-technical
"Since when is the cover letter mandatory? I understand that is helps for a complicated patch set to explain the problem and solution in the cover letter, but for this simple test case addition what's the point? And there is nothing forcing a cover letter in this. Also double tags seams to be quite common for selftest. See this.",non-technical
"I'm not sure that forcing a library on users is a good reason to break UAPI.The patch is going into the latest, but can also be backported on future stables.I don't think ""not fixing it because it's not fixed yet"" is a good reason to keep things the way they are. But maybe that's just me. Given that the structure has already been extended several times, there is pretty much nothing to keep this from happening again and again.",non-technical
"Thats a misleading statement.  We've never supported running newer applications on older kernels, and no one is forcing anyone to use the lksctp-tools library, I was only suggesting that, if we were to support this compatibility, that might be a place to offer it.Its also worth noting that we have precident for this.  If you look at the gitlog, this particular structure has been extended about 6 times in the life of sctp. Also misleading, as it assumes that we're not intentionally doing this.  I get wanting to support running applications built for newer kernels on older kernels, but thats just not something that we do, and to say thats broken is misleading.  Older applications are required to run on newer kernels, but not vice versa, which is what you are asking for.And yes, this patch can be backported to older stable kernels, but by that same token, so can the patches that extend the struct, which would also fix the problem, while supporting the newer features, which seems to me to be the better solution for applications which are looking for that support.",non-technical
"What a complete mess we have here. Use new socket option numbers next time, do not change the size and/or layout of existing socket options. This whole thread, if you read it, is basically ""if we compatability this way, that breaks, and if we do compatability this other way oh shit this other thing doesn't work."" I think we really need to specifically check for the difference sizes that existed one by one, clear out the part not given by the user, and backport this as far back as possible in a way that in the older kernels we see if the user is actually trying to use the new features and if so error out. Which, btw, is terrible behavior.  Newly compiled apps should work on older kernels if they don't try to use the new features, and if they can the ones that want to try to use the new features should be able to fall back when that feature isn't available in a non-ambiguous and precisely defined way.The fact that the use of the new feature is hidden in the new structure elements is really rotten. This patch, at best, needs some work and definitely a longer and more detailed commit message.",non-technical
"There probably is a decent compromise to find between ""not accepting a single additional byte"" and accepting several GB.For example how likely is it that the growth of this structure make it go over a page? I would hope not at all. By choosing a large but decent high limit, I think we can find a future-compatible compromise that doesn't rely on this just for structure trucation decision...",non-technical
"I disagree with this, at least as a unilateral statement.  I would assert that an old program, within the constraints of the issue being discussed here, will run perfectly well, when built and run against a new kernel.At issue is the size of the structure sctp event subscribe, and the fact that in several instances over the last few years, its been extended to be larger and encompass more events to subscribe to. Nominally an application will use this structure (roughly) as follows. Assume this code will be built and run against kernel versions A and B, in which: A) has a struct sctp event subscribe with a size of 9 bytes B) has a struct sctp event subscribe with a size of 10 bytes (due to the addedfield sctp sender dry event) 
That gives us 4 cases to handle
1) Application build against kernel A and run on kernel A.  This works fine, the sizes of the struct in question will always match
2) Application is built against kernel A and run on kernel B.  In this case,everything will work because the application passes a buffer of size 9, and the kernel accepts it, because it allows for buffers to be shorter than the current struct sctp event subscribe size. The kernel simply operates on the options available in the buffer.  The application is none the wiser, because it has no knoweldge of the new option, nor should it because it was built against kernelA, that never offered that option
3) Application is built against kernel B and run on kernel B.  This works fine for the same reason as (1).
4) Application is built against kernel B and run on kernel A.  This will break because the application is passing a buffer that is larger than what the kernel expects, and rightly so.   The application is passing in a buffer that is incompatible with what the running kernel expects.We could look into ways in which to detect the cases in which this might be'ok', but I don't see why we should bother, because at some point its still an error to pass in an incompatible buffer.  In my mind this is no different than trying to run a program that allocates hugepages on a kernel that doesn't support hugepages (just to make up an example).  Applications built against newer kernel can't expect all the features/semantics/etc to be identical toolder kernels.It shouldn't.  Assuming you have a program built against headers from kernel B(above), if you set a field in the structure that only exists in kernel B, and try to run it on kernel A, you will get an EINVAL return, which is correct behavior because you are attempting to deliver information to the kernel that kernel A (the running kernel) doesn't know about.  Thats correct behavior.I won't disagree about the niceness of versioning, but that ship has sailed.To be clear,  this is situation (1) above, and yeah, running on the kernel you built your application against should always work from a compatibility standpoint.Yes, but this is alawys the case for structures that change.  If you have an application built against kernel (B), and uses structure fields that only exist in that version of the kernel (and not earlier) will fail to compile when built against kernel (A) headers, and thats expected.  This happens with any kernel api that exists in a newer kernel but not an older kernel .Any time you make a system call to the kernel, you have to be prepared to handle the resulting error condition, thats not unexpected.  To assume that a system call will always work is bad programming practice.",non-technical
Looking more flexible does not make it more correct.,non-technical
"This is indeed guaranteed. For FTRACE use case. If it's being called from FTRACE in run time, this would mean there were long calls in this module section, which inturn means, get module plt() was called at least once for this module and this section. This doesn't hold in general, though.In any case, if you insist, I can try to rework the whole stuff implementing module finalize().",non-technical
So make it fit by returning an unsigned int. Good mailing practices for 400: avoid top-posting and trim the reply.,non-technical
"Thank you so much for many style, formatting and other issues fixes and also forintegration of 'check at most once' patch, it saved me several review iterations. Regarding free of sg in two error paths, you were correct.I fixed it by placing several error labels to differentiate each handling. I also noted that was not released properly, this is also fixed. following is a diff of my fix based on your modifications.(I can send it in a patch format, but it doesn't include a fix for Eric Biggers comments) I took your modifications and working upon it.",non-technical
"The driver is looking good! It looks like you've done some kind of review that we weren't allowed to see, which is a double edged sword - I might be asking about things that you've already spoken about with someone else. I'm only just learning about PECI, but I do have some general comments below. I think just saying ASPEED PECI support is enough. That way if the next ASPEED SoC happens to have PECI we don't need to update all of the help text :) Nit: we use ASPEED instead of AST in the upstream kernel to distingush from the aspeed sdk drivers. If you feel strongly about this then I won't insist you change. I know these come from the ASPEED sdk driver. Do we need them all? Could the above use regmap read poll timeout instead? That looks like an endian swap. Can we do something like this? Having #defines is frowned upon. I think print hex dump debug will dowhat you want here.I find this hard to read. Use a few more lines to make it clear what your code is doing. Actually, the entire for loop is cryptic. I understand what it's doing now. Can you rework it to make it more readable? You follow a similar pattern above in the write case. Given the regmap read is always going to be a memory read on the aspeed, I can't think of a situation where the read will fail. On that note, is there a reason you are using regmap and not just accessing the hardware directly? regmap imposes a number of pointer lookups and tests each time you do a read or write. Again, a memory mapped read won't fail. How about we check that the regmap is working once in your  probe() function, and assume it will continue working from there (or remove the regmap abstraction all together). All of this code is for debugging only. Do you want to put it behind some kind of conditional? We have a framework for doing clocks in the kernel. Would it make sense to write a driver for this clock and add it to this? The property is optional so I suggest we don't print a message if it's not present. We certainly don't want to print a message saying ""invalid"". The same comment applies to the other optional properties below. Can we probe in parallel? If not, putting a sleep in the  probe will hold up the rest of drivers from being able to do anything, and hold up boot.If you decide that you do need to probe here, please add a comment.(This is the wait for the clock to be stable?) This interrupt is only for the peci device. Why is it marked as shared?",non-technical
"According to my comment on the other thread, this stands true in case the child is managed by runtime PM as well.Otherwise this looks good to me. How about adding an additional patch on top taking into account the ignore children flag and folding that into the series, kind of as you also suggested?My point is, we might as well take the opportunity to fix this right away, don't you think? ",non-technical
I'm really sorry for this. could you please illustrate me what the kconfig & warning is?I didn't get such warnings from 0-day. ,non-technical
I'm not the one that added this switch statement (it has been there since 2011) and I would be happy to remove it.  However could we please defer this to v4.17 and merge the current set of Exynos thermal fixes/cleanups (they simplify the driver a lot and make ground for future changes)?,non-technical
"Thanks for your reply :) I admit I am not familiar with this driver. I did not know this driver is only loaded during system boot-up time, I thought this driver can be loaded as a kernel module (like many drivers) after system booting. After knowing this, I admit my patch is not proper, sorry...",non-technical
"Well, I am not sure. Could you please give me hints, how to debug this further? Is there some debug flag? I am only aware of the Ftrace framework, but in my experience it also skews the timings quite a bit, so might not be the best choice. ",non-technical
I see I've missed some obvious things that you've pointed out here. I'll mark these warnings as False Positives and take your points into account for the analysis of the rest of the Spectre issues reported by Smatch.Sorry for the noise and thanks for the feedback. ,non-technical
"Hi, Please, drop this series. Further analysis is required as it seems all these are False Positives. Sorry for the noise.",non-technical
"Thanks for a comprehensive explanation about that. It now makes more sense to me. Yeah, better to apply a fix to avoid the issue with VIDIOC ENUM FMT. Btw, on almost all media drivers, the implementation for enumerating the supported formats are the same (and we have a few other VIDOC ENUM fooioctls that usually do similar stuff): the V4L2 core calls a driver, with looks into an array, returning the results to the core. So, a fix like that should likely go to almost all media drivers (there are a lot of them!), and, for every new one, to take care to avoid introducing it again during patch review process.So, I'm wondering if are there any way to mitigate it inside the core itself, instead of doing it on every driver. Ok, a ""poor man"" approach would be to pass the array directly to the core and let the implementation there to implement the array fetch logic, calling this there, but I wonder if are there any other way that won't require too much code churn. ",non-technical
"please don't submit such a huge number of patches all at one time. Also, please fix the indentation of the functions whose arguments span multiple lines as has been pointed out to you in patch feedback. Finally, make this a true patch series.  It is so much easier for maintainers to work with a set of changes all doing the same thing if you make them a proper patch series with an appropriate ""[PATCH 0/N] ...""header posting. Thank you.",non-technical
"One of the basic questions/concerns I have is accounting for surplus huge pages in the default memory resource controller.  The existing huegtlb resource controller already takes hugetlbfs huge pages into account, including surplus pages.  This series would allow surplus pages to be accounted for in the default  memory controller, or the hugetlb controller or both. I understand that current mechanisms do not meet the needs of the aboveuse case.  The question is whether this is an appropriate way to approach the issue.  My cgroup experience and knowledge is extremely limited, but it does not appear that any other resource can be controlled by multiple controllers.  Therefore, I am concerned that this may be going against basic cgroup design philosophy.It would be good to get comments from people more cgroup knowledgeable, and especially from those involved in the decision to do separate hugetlb control",non-technical
"I am sorry that I didn't join the discussion for the previous version but time just didn't allow that. So sorry if I am repeating something already sorted out. There was a deliberate decision to keep hugetlb and ""normal"" memory cgroup controllers separate. Mostly because hugetlb memory is an artificial memory subsystem on its own and it doesn't fit into the rest of memcg accounted memory very well. I believe we want to keep that status quo. Well such a use case requires an explicit configuration already. Either by using special wrappers or modifying the code. So I would argue that you have quite a good knowlege of the setup. If you need a greater flexibility then just do not use hugetlb at all and rely on THP.[...]I do not really think this is a good idea. We really do not want to make the current hugetlb code more complex than it is already. The current hugetlb cgroup controller is simple and works at least somehow. I would not add more on top unless there is a really strong usecase behind. Please make sure to describe such a usecase in details before we evenstart considering the code. Well, then I would argue that you shouldn't use 64kB pages for your setup or allow THP for smaller sizes. Really hugetlb pages are by no means a substitute here.--",non-technical
"No problem, at the beginning, I only wanted to enable the strict. Doing this involves that I have to remove pinctrl nodes for the pins which are going to be request through the gpiolib to avoid conflicts. These pinswere configured with bias-pull-up. That's why I try to add the bias support.Thanks for the detailed answer about what you have in mind.Well, yes and not! As a consequence of enabling strict mode, I have tofind another way to configure the pins. Yes, I have noticed this issue. Right, I have spotted some drivers to fix.I will try to handle the ones related to the platforms I am using. ",non-technical
"I apologize for having confused.The hugetlb pages obtained from the pool do not waste the buddy pool. On the other hand, surplus hugetlb pages waste the buddy pool. Due to this difference in property, I thought it could be distinguished.Although my memcg knowledge is extremely limited, memcg is accounting forvarious kinds of pages obtained from the buddy pool by the task belonging to it. I would like to argue that surplus hugepage has specificity interms of obtaining from the buddy pool, and that it is specially permitted charge requirements for memcg.It seems very strange that charge hugetlb page to memcg, but essentiallyit only charges the usage of the compound page obtained from the buddy pool,and even if that page is used as hugetlb page after that, memcg is not interested in that. I will completely apologize if my way of thinking is wrong. It would be greatly appreciated if you could mention why we can not charge surplus huge pages to memcg. I could not understand the intention of this question, sorry. When resize the pool, I think that the number of surplus huge pages in use does not change. Could you explain what you were concerned about?",non-technical
"I do not see anything like that. adjust pool surplus is simply and As you said, my patch did not consider handling when manipulating the pool. And even if that handling is done well, it will not be a valid reason to charge surplus huge page to memcg. I understood the concept of memcg. As you said, it must be an alien. Thanks to the interaction up to here, I understood that my solution is inappropriate. I will look for another way.Thank you for your kind explanation.",non-technical
"I'm not sure I understand what you intend here. If   sync blockdev fails, then the error should have already been marked in (via patch #6). We wouldn't want to record that again at syncfs time.Note that   sync blockdev will return errors based on the legacy flags.We really do need to record it in the superblock as soon as possible after an error occurs. If we want to allow userland to eventually beable to scrape this value out of the kernel (as we discussed at LSF/MM)then we can't assume that it'll be doing any sort of syncfs call before hand.The main reason to push this down into the filesystems is to allow them control over whether to report errors at syncfs time via the super blocker rseq t or not. If we don't really care about allowing this to be an opt-in thing, then we could just take the patch that I sent on April 17th write back errors and report them to syncfs We'd also want patch #6 from this series, I think, but that's more or less enough to implement this over all filesystems, assuming they use mapping set error to record writeback errors. I'm fine with either approach.",non-technical
"Please don't top post. And wrap your lines at around 75 characters Look closely at the two implementations. Look at whatmmd phy indirect() does. I think these are identical. So don't add your own helper, please use the core code.     ",non-technical
"Oops, sorry, I double posted patch 5. Please disregard the second one. ",non-technical
"Well, clients not checking the error code made this harder to debug for sure, but removing the error code is a side effect and not what is happening here (in fact someone should probably still go back and add error checking because these functions can still return errors but that's not really something I have time to do). After the next couple patches, the clients will use this change to detect that there are no port numbers and handle things similarly to the way they did before they were broken by the multiport changes.This is the opposite of what I've ever heard before. Having a commit message that explains what led up to this commit is a good thing and allows people debugging in the future to better understand the decisions made. People debugging commits will never find the 0/X cover letter which is just intended to introduce the series to reviewers and describe changes if the series is posted multiple times. No this is not a feature request. This is fixing a regression that broke previously working code in the only sensible way I can come up with. If you have a better way to fix this, I'd be glad to hear it. But this should *not* be treated as a feature request.",non-technical
"The commit description is not quite correct.  What the flag does is allow a discard request for those block devices which do not have the flag.I will note that the  flag is a bit controversial in linux-fsdevel.  I have a similar patch in the VFS inGoogle's internal data center kernel, as well as an internal patch which implements support for this flag in ext4.  However, the patches are out of tree, because pretty much all of the file system developers who work for enterpise distributions were against this functionality. I know of one other major cloud provider (in China) using the functionality as an out-of-tree patch, but with no one else speakingin favor of it, and everyone else NAK'ing the patch and enterprise distro's saying they would revert the patch in their distro kernels,the compromise we came to was that the code point for NO HIDE STALE FL would be reserved so that users of the out-of-tree patches wouldn't collide with future fallocate flags; and I would stop trying to push the patches upstream.I have no idea how Darrick was able to get commit upstream, but I guess it was less controversial for block devices than for file systems.So I'm certainly in favor of this patch landing in mainline, but you should be aware that there may be some opposition to it. ",non-technical
I can't take patches without any change log text at all :(,non-technical
"As far as I can tell, the above is the whole reason for the patch set,yes?  To avoid confusing users.Is that sufficient?  Can we instead simplify their lives by providing better documentation or informative printks or better Kconfig text, etc?And who *are* the people who are performing this configuration?  Random system administrators?  Linux distro engineers?  If the latter then they presumably aren't easily confused! In other words, I'm trying to understand how much benefit this patch set will provide to our users as a whole.",non-technical
"Hopefully I'm not missing anything here, but this doesn't really make any sense. I'm not sure I explained myself as well as I thought I did. To behonest, I had to double check this about literally 20 times to make sure I was actually understanding this issue correctly. Turns out I was missing a couple of parts, so I'm going to try again at explaining this using a diagram that shows the various threads running concurrently phew. that took a LONG time to come up with. Anyway-that's why your explanation doesn't make sense: the deadlock is happening because we're calling pm runtime get sync(). If we were to make that call conditional, all that would meanis that we wouldn't grab any runtime power reference and the GPU would immediately suspend once the atomic commit finished, as the suspend request inThread 5 would finally get unblocked and thus----suspend. Hopefully I explained that better this time, I'll definitely make sure to actually include that diagram in the patch. As for whether or not this patch is even the right solution, I will need to confirm that tommorrow (if you don't think it is still, please feel free to say so!) because it's getting late here. ",non-technical
"Thanks a lot for all this work! It was long overdue and it is nice to see the project finally getting to an end, after passing into so many hands! I am not sure I understand the purpose of this level here. As far as I understand, you only have per-engine control whether you want to enable CG or not. What you call BLCG and SLCG levels just mean ""don't use the boot values, but rather use our values (taken from nvidia)"". Now, here comes the nasty part: NVIDIA only ever validated the boot values (I guess they are extremely safe ones), and the optimised values (the ones coming from your patch 2, 3, and 4 along with the level 3. I think introducing a single parameter that controls both CG, PG, and automatic reclocking would be safer. For CG and PG, it would be aall-or-nothing (either boot values, or everything like nvidia).This message is a bit odd, whether we keep the notion of levels or not. Can you get rid of the mention of powergating given that this is notpart of this patchset?If you agree with having a single enable bit for CG, then a simple:""Clockgating status: (boot | optimized)"" would work perfectly.All this time, I thought these parameters were for power gating... I also did not expect that clock gating had to be disabled before we could program them. Great find! Why introduce this? I can't find references to it in this patch (outside of the function below) or in the following patches.As you even export this function, it looks like you used to use thisfunction in an earlier revision of this series.Aside from all these nitpicks, the approach is quite self contained andI like the following patches. Well done!Once we settle on the configuration parameter, I can give you.",non-technical
"First of all, I was mistaken when I wrote above that a check for! worker would solve the problem.  Sorry! It doesn't because the call to this is not happening in it but in work. Looking once more at the three stack traces you've provided, we've got:- For the moment we can ignore the first task, i.e. execute,and focus on the latter two.As said I'm unfamiliar with MST but browsing through topology.cI notice that it is the ->work element and is queued on HPD.  I further notice that the work item is flushed on And before the work item is flushed, the HPD source is quiesced.So it looks like work can only ever run while the GPU is runtime resumed, it never runs while the GPU is runtime suspended.  This means that you don't have to acquire any runtime PM references in or below work. Au contraire, you must not acquire any because it will deadlock while the GPU is runtime suspending.  If there are functions which are called from work as well as from other contexts,and those other contexts need a runtime PM ref to be acquired, you need to acquire the runtime PM ref conditionally on not being work (using the current work() technique). Alternatively, move acquisition of the runtime PM ref further up in the call chain to those other contexts. Right, that seems to be a bug suspend:If a display is plugged in while the GPU is about to runtime suspend,the display may be lit up by execute but the GPU will then nevertheless be powered off. I guess after calling disable we should re-check if a crtc has been activated.  This should have bumped the runtime PMrefcount and have disp power ref should be true.  In that case, the suspend should return -EBUSY to abort the runtime suspend.The same check seems necessary after flushing it:If the work item lit up a new display, all previous suspend steps needto be unwound and -EBUSY needs to be returned to the PM core. Communication with an MST hub exceeding the autosuspend timeout is just one scenario where this bug manifests itself. BTW, disable seems to be called twice in the runtime suspend code path, once in this and a second time in this.A stupid question, I notice that it calls this? Why isn't that? ",non-technical
"Just a blind shot, without going into details - could you please check if led-sources property documented in the common LED bindings couldn't help here?",non-technical
Hi! This is better than my proposal. Thanks!,non-technical
"I welcome this feature, been wanting it for some time now. There is simply not enough support in maps or smaps to get this information. This is important to improve code and data layouts.I would like to see the following changes to your proposal. That would allow two things. In some measurements, you may just care about the distribution of accesses across page sizes. No need to use double the buffer space to save the address you will not use. Layout is important for code as well, in fact, that's what most peoplewant first. Having a CODE PAGE SIZE is therefore useful. I am happy adding it on top on your proposal. Note that it would not have to be tied to PEBS unlike this.Thanks.",non-technical
Please use your real name. 1st Signed-off-by and patch author should match. Good find! I'll queue this for the next fixes-pull-request.,non-technical
"Interesting - I don't see the grant head reservation code in any of my performance benchmark profiling, even when running at over a million transactions on a 2-socket 32-core 64-thread skylakesystem. I see other places in the transaction subsystem that are hot (e.g the CIL context lock), but not the space reservations. My initial suspect is that you have a tiny log on your test file system, so it's permanently out of space and so always hitting the slow path. Can you tell us what the storage is and it's configuration? At minimum, I need to see the output of the xfs infocommand on your test filesystem. Fixing this may simply be using alarger log on your benchmark systems. FWIW, can you post the actual profile you are seeing in the commit message? That helps us identify similar problems in the future, andit lets us know what paths are leading to the transaction reservation contention. i.e. this may not even be a problem with the transaction reservation code itself. How does this impact on the strict FIFO queue behaviour the grantqueues currently have? The current code only wakes up enough waiters to consume the newly available space and it queues new waiters to the tail of the queue. If there ever is a spurious wakeup then the waiter that was woken from the head remains there until the next wakeup comes in. This is intentional - spurious wakeups are rare enough we can ignore them because a) this is the slow path, and b) correctness is far more important that performance in this path. The fast path is already lockless, and we've already given up peformance if we reach this slow path. hence we only care about correctness in this path, not performance optimisation.AFAICT the patch changes the spurious wakeup behaviour - it requeues tasks to the tail of the queue if there wasn't space available when they are woken, rather than leaving them as them at the head.  They now have to wait for all the other reservations to make progress.This breaks the guarantees of ordered forward progress the grant queue provides permanent transaction reservations and hence opens us up to log space deadlocks because those transactions can't move their objects forward in the log to free up space in the log...Also, I note that wake q add() assumes that the wake queue is a local stack object and so not subject to concurrency - it explicitly states this in the code. That's not the case here - the wake queue is part of the grant head, and so is subject to extreme concurrency that is tempered by a spin lock.  Does the wake q code work correctly (e.g. have all the necessary memory barriers, etc) whenit's not a local stack object and instead protected from concurrency by a spin lock? At minimum, the wake q infrastructure comments and documentation need updating to accommodate this new use case that wake queues are being used for.This doesn't generally doesn't happen because the space accounting tends to prevent multiple wakeups. i.e. we only wake the tasks we have reservation space for, and log space being made available tends to arrive in discrete chunks (because IO is slow!) such that that pending wakeups have already been processed before the next chunk of available space comes in....Yes, but they are very rare and we don't really care about this in the slow path. If you see lots of them, it's typically a sign of an inappropriately configured filesystem for the workload being run. On a correctly configured system, we should almost never use this slowpath....I'm betting that you'll get that and a whole lot more simply byincreasing the log size and not running the slow path at all. Where's the hunk context in your headers? You must be using anon-standard git option here. Linux kernel specific includes go in this not individual files. Why do you need to delete the ticket from the queue here? This leads to landmines and incorrect non-FIFO behaviour....... here. This is a potential list corruption landmine because this function now has unbalanced list add and removal contexts. IOWs, we can't restart this loop without first having guaranteed the ticket is not already on the ticket queue. You need to document constraints like this in comments and explain what code needs to guarantee those constraints are met. [Because, as I noted at the end, you got thiswrong for xlog grant head wake all()] To maintian FIFO behaviour, the ticket needs to be left at the head of the grant head wait queue until it has space available to make progress, not get removed and requeued to the tail. Spurious wakeups are irrelevant here - forwards progress (i.e. correctness) requires FIFO ticket ordering behaviour be maintained.This push is needed to make the necessary space we are waiting on available in the log. Hence leaving it out of the loop you put below will cause the journal to get stuck in the spurious wakeuploop below and be unable to make progress. This will lead to filesystem hangs.That's a new nested loop. Please implement it as a loop. This is buggy  - i will lead to hangs if the filesystem is shutdown and there is a spurious wakeup that triggers this to go back to sleep.The shutdown check needs to break the sleep loop. That's racy. You can't drop the spin lock betweenxlog grant head wake() and xlog grant head wait(), because free bytes is only valid while while the spinlock is held.  Same for the ""wake all"" variable you added. i..e. while waking up the waiters, we could have run out of space again and had more tasks queued, or had the AIL tail move and now have space available. Either way, we can do the wrong thing because we dropped the lockand free bytes and wake all are now stale and potentially incorrect.That's another landmine. Just define the wakeq in the context where it is used rather than use a function wide variable that requires reinitialisation. Ok, what about wake all? You didn't convert that to use wake queues, and so that won't remove tickets for the granthead waiter list, and so those tasks will never get out of the new inner loop you added to xlog grant head wait(). That means filesystem shutdowns will just hang the filesystem and leave it unmountable. Did you run this through fstests? ",non-technical
"Thanks for your detailed review of the patch. I now have a betterunderstanding of what should and shouldn't be done. I have sent out amore conservative v2 patchset which, hopefully, can address the concerns that you raised",non-technical
"Can you please re-run and report the results for each patch on the ram disk setup? And, please, include the mkfs.xfs or xfs info output for the ramdisk filesystem so I can see /exactly/ how much concurrency the filesystems are providing to the benchmark you are running. 50GB is tiny for XFS. Personally, I've been using ~1PB filesystems(*) for the performance testing I've been doing recently... ",non-technical
"I like the idea and I think it's good direction to go, but could you please share some from perf stat or whatever you used to meassure the new performance?",non-technical
"Sorry but I don't like imposing a run-time check on everybody when stack-based requests are the odd ones out.  If we're going to make this a run-time check (I'd much prefer a compile-time check, but I understand that this may involve too much churn), then please do it for stack-based request users only. ",non-technical
"Sorry about being late, just returned home and am trying to get all the backlogs under control. I remember the PPP standard is a bit cloudy about the possible issue, but the latter indeed exists (the PPP state machine was written directly to STD-51). There is related (more visible in practice, though we aren't affected) issue of ""active"" vs ""passive"" mode (hdlc ppp.c is ""active"",and two ""passives"" wouldn't negotiate at all). Anyway the problem is real (though not very visible in practice, especially on relatively modern links rather than 300 or 1200 bps dialupconnections) and should be fixed. Looking at the patch, my first impression is it makes the code differ from STD-51 a little bit. On the other hand, perhaps applying it as is and forgetting about the issue is the way to go. Ideally, I think the negotiation failure should end up (optionally, inaddition to the current behavior) in some configurable sleep, then the negotiation should restart. If it's worth the effort at this point,I don't know. Perhaps I could look at this later, but no promises (this requires pulling on and setting up some legacy hardware). Anyway, since the patch is safe and can solve an existing problem.",non-technical
"I am not subscribed to LKML, please keep me CC'd on replies. I tried a simple test with several VMs (in my initial test, I have 48 idle 1-cpu 512-mb VMs and 2 idle 2-cpu, 2-gb VMs) using libvirt, none pinned to any CPUs. When I tried to set all of the top-level libvirt cpuc groups' to be co-scheduled the machine hangs. This is using cosched max level=1.There are several moving parts there, so I tried narrowing it down, by only coscheduling one VM, and thing seemed fine One thing that is not entirely obvious to me (but might be completely intentional) is that since by default the top-level libvirt cpu cgroups are empty. cat tasks the result of this should be a no-op, right? [This becomes relevant below] Specifically, all of the threads of qemu are in sub-cgroups, which do not indicate they are co-scheduling: When I then try to coschedule the second VM, the machine hangs. On the console, I see the same backtraces I see when I try to set all of the VMs to be coscheduled: am happy to do any further debugging I can do, or try patches on top of those posted on the mailing list.",non-technical
"There seems to be a disconnect between what I am trying to communicate and what I perceive you to have understood. I'll add comments below to try to make more clear what I'm trying to say.But first a general statement.  I understand that the intent of the patch wording is to allow use of email addresses in the tags of a patch submittal or git commit without being an unacceptable behavior.  I do not think that the words in the patch accomplish that goal.The patch says ""Publishing ... electronic address not ordinarily collected by the project, without explicit permission"".  (I think it is fair to abstract here with ""..."".)  This phrase specifies which email addresses can be published.  It does not specify in what casesthe email address can be published.  The desired goal is to be able to publish email addresses in patch and commit tags. Which email addresses are allowed to be published?  (This is the point of my original comment.)  To me, the patch wording is describing how I can determine whether I can put a specific email address in a tag in a patch that I submit or commit.  I can put an email address in a tag  if  it is ""ordinarily collected by the project"".This then leads my mental process down the path of the disclosures (from all of the companies that I do business with) that tell me what they are going to do with my personal information, such as my address.  (They usually plan to share it with the world for their financial benefit.) In that context, my personal information is not  public , but it is ordinarily collected  by the company.  I hope this provides some insight into what I am reading into ""ordinarily collected by the project"". My original comment was trying to provide the concept behind a way tocreate an alternate wording in the patch to define ""which email addresses"". Where are email addresses allowed to be published?  I do not understand the patch wording to address this at all. Trying to understand how you are understanding my comment vs what I intended to communicate, it seems to me that you are focused on the ""where allowed"" and I am focused on the ""which email addresses"". More clear?  Or am I still not communicating well enough? Permission vs exclusion is orthogonal to my comments. ""building linux"" is not the patch wording.  ""ordinarily collected by the project"" is a much broader universe. A very simplistic definition of public  could  be:- Visible on a project mail list that any one can subscribe to- Visible on a project mail list whose archive is available via the public internet- Visible on an interactive communication (""chat"") platform thatis open to the public internet- Published on a web page intended for public access (for example this could cover opt-in conference attendee lists and emails that conference presenters voluntarily place in their slides).- (I am guessing the above covers 97% or more of possible publicsources, but maybe there are some more common sources.) I'm sure that the professionals that deal with information privacy could provide better wording for the above list.  I am but an amateur in that field. Anything else collected by the project would not be considered public. For example, an email address provided in an email sent to me and not copied to any mail list would not be public.",non-technical
"I would really like to get an ack from the people who have been deep into this first.  If you can get that, and preferably resubmit with a less condescending changelog, I can pick it up.",non-technical
"is this patchset still an RFC or you really want to see this merged ASAP? If I am not mistaken there is still some work in progress trying to push all the SCP stuff? Lee, personally I have some concerns. Looks like the cros * family is increasing quickly lately and I am wondering if we are really doing well all this.To be honest, I'd like to take a deeper look before merge this, btw Ithought there was no hurry because of the RFC and I guess there are still some scp things that are missing. I might be wrong, and if that's not the case I can take a look deeper and the end of the week. ",non-technical
"You are missing a cover letter from this patch set. Please have it inv2. Also use tag ""selftests/tpm2"" instead of having two tags in the short summaries. Now they look a bit weird. ",non-technical
This is phenomenal. Thank you so much for digging into this. I'm hoping this will greatly reduce the risk of future leakage.,non-technical
"I mean the level of a resource in IOMEM tree (the one that's printed from this). 1-st level means its parent is root and so on. If it's not a problem anymore IIUC, can we revert the change as it still breaks. for the reasons I described above? Nothing prevents - true, but that's plainly wrong from OS point of view to grab physical ranges for something without knowing what's actually behind on that platform. I think we shouldn't consider this as a valid thing to do and don't try to work around initially incorrect code.",non-technical
"How do you plan to handle the external references? For example, the following LWN articles has a link this file:",non-technical
"IMO symlinks are mostly ending in a mess, URLs are never stable.There is an object to handle such requirements. Take a look at *intersphinx* to see how it works:  Each Sphinx HTML build creates a file named objects.inv thatcontains a mapping from object names to URIs relative to the HTML set€™s root. This means articles from external (like lwn articles) has to be recompiled. Not perfect, but a first solution. I really like them, factually valuable comments .. please express your concern so that we have a chance to move on. I think that's a pity.-",non-technical
"So I hate this rst crap with a passion, so NAK from me.",non-technical
"How  do you think my patch? As you see, he think my patch is ok to be accepted. But if you have a better idea to fix it, I am glad to see it. Anyway, this issue have to be fixed. Denis DU Denis Du writes:Sorry about being late, just returned home and am trying to get all the backlogs under control. I remember the PPP standard is a bit cloudy about the possible issue, but the latter indeed exists (the PPP state machine was written directlyto STD-51). There is related (more visible in practice, though we aren't affected) issue of ""active"" vs ""passive"" mode (hdlc ppp.c is ""active"",and two ""passives"" wouldn't negotiate at all). Anyway the problem is real (though not very visible in practice, especially on relatively modern links rather than 300 or 1200 bps dialup connections) and should be fixed. Looking at the patch, my first impression is it makes the code differ from STD-51 a little bit. On the other hand, perhaps applying it as is and forgetting about the issue is the way to go.Ideally, I think the negotiation failure should end up (optionally, in addition to the current behavior) in some configurable sleep, then the negotiation should restart. If it's worth the effort at this point,I don't know. Perhaps I could look at this later, but no promises (this requires pulling on and setting up some legacy hardware). Anyway, since the patch is safe and can solve an existing problem.",non-technical
"A version of this patch has been queued by Catalin. Now that the cpu feature bits are queued, I think this can be split up into two separate series for v4.16-rc1, one to tackle NOTIFY SEI and the associated plumbing. The second for the KVM 'make SError pending' API. I didn't sign-off this patch. If you pick some bits from another version and want to credit someone else you can 'CC:' them or just mention it in the commit-message. Irrelevant-Nit: sys-regs usually have a 'SYS ' prefix, and are in instruction encoding order lower down the file.(These PSTATE PAN things are a bit odd as they were used to generate and instruction before the fancy helpers were added). Bits of this are spread between patches 5 and 6. If you put them in the other order this wouldn't happen.(but after a rebase most of this patch should disappear) So this writes an impdef ESR, because its the existing code-path in KVM. And then you overwrite it. Which is a bit odd as there is a helper to do both in one go: How come you don't use this in this?",non-technical
"For do you report a speed of 2500Mbps through eth tool, or are you reporting 1000Mbps?  I don't see any code in this patch that deals with that.--RMK's Patch system broadband for 0.8mile line in suburbia: sync at 8.8Mbps down 630kbps up According to speedtest.net.",non-technical
"Can you please use a consistent name space? retpoline  ... or such?I really don't like fiddling with that variable. That's just hackery. The variable reflects the actual enabled mitigation state of the kernel proper. That'll break once we get other mitigation variants.These newlines are there to separate stuff for readability sake. This really can be done in a cleaner way. That only needs one function and that one can take care of setting avariable in the spectre code which then influences the sysfs output. And that output should not be ""Vulnerable"" like you force with the hackabove. It actually should tell WHY it is vulnerable despite having had protection in place before the module was loaded. ",non-technical
I didn't get any response to a comment I've written about the pointabove during the previous patch iteration. The old code set this bit in any mode other than AC'97 ,non-technical
This does not make sense vs. the documentation: This should say:And I really have to ask whether this should be named  GLOBAL  instead of SHARED . Hmm?,non-technical
"Again, 'boutside' protection ...Other than that.",non-technical
"The timer is supposed to restart the protocol again, that's how this whole thing is designed to work.I think you are making changes to the symptom rather than the true cause of the problems you are seeing. Sorry, I will not apply this until the exact issue is better understood.Thank you.",non-technical
"I cannot apply a patch which has been corrupted by your email client like this. Please send it properly again, plain ASCII text, and no trasnformations by your email client. You should send the patch to yourself and try to apply the patch you receive, do not send to the list until you can pass the test properly. Do not use attachments to fix this problem, the patch must be inline after your commit message and signoffs. Please read Documentation for more information. Thank you.",non-technical
"Ok, I check the source code again. It have nothing to do with the interrupts, it is related how the hdlc.c is implemented. It will do nothing, not start any new protocol and thus the timer.My case is the carrier always good, but protocol will fail due to perfect noise, and this issue was found and complained by our customers. So it is not my theory guessing, it is a real problem. ",non-technical
"Please don't put plain-text files into core-api - that's a directory full of RST documents.  Your document is 99.9% RST already, better to just finish the job and tie it into the rest of the kernel docs. We might as well put the SPDX tag here, it's a new file. This is all good information, but I'd suggest it belongs more in the 0/npatch posting than here.  The introduction of *this* document should say what it actually covers.This seems like a relevant and important aspect of the API that shouldn't be buried in the middle of a section talking about random things.So one gets this far, but has no actual idea of how to do these things. Which leads me to wonder: what is this document for?  Who are you expecting to read it?You could improve things a lot by (once again) going to RST and using directives to bring in the kerneldoc comments from the source (which, I note, do exist).  But I'd suggest rethinking this document and itsaudience.  Most of the people reading it are likely wanting to learn how to *use* this API; I think it would be best to not leave them frustrated. ",non-technical
"Thanks for the review and apologies for the delay. Replies inlined below. ]okok, this is all new stuff to me ... I suppose I should do it also for all the other new files I create But what is the license for the documentation? It's not code, so GPL seems wrong. Creative commons? I just noticed a patch for checkpatch.pl about SPDX and asked the same question there. I'll move it to the Use section.[...]I will add a reference to the self test file. In practice it can also work as example.ok, the example route should be more explicative.--thanks again for the review.",non-technical
"Relatively significant? I do not object to your comment, but in practice i see that:- vmalloc is used relatively little- allocations do not seem to be huge- there seem to be way larger overheads in the handling of virtual pages  (see my proposal for the LFS/m summit, about collapsing struct   vm struct and struct vmap area) Can you please point me to this function/macro? I don't seem to be able to find it, at least not in 4.15 During hardened user copy permission check, I need to confirm if the memory range that would be exposed to userspace is a legitimate sub-range of a pmalloc allocation. So, I start with the pair (address, size) and I must end up to something I can compare it against. The idea here is to pass through struct page and then the relatedvm struct/vmap area, which already has the information about the specific chunk of virtual memory. I cannot comment on your proposal because I do not know where to find the reference you made, or maybe I do not understand what you mean ",non-technical
You can't do it this simply as it will cause deadlock due to nested locking of the buf lock. To share the lock you will need to provide unlocked versions of the read and write functions and use those if the lock has already been taken.,non-technical
Ok. I've looked at your patch for way too long now and still don't see how you've shown it to be correct. Shouldn't there be a at least a comment to explain why zero is an appropriate initialization value in that case?,non-technical
Are you moving checks from the core subsystem to drivers ? This looks really nonsensical and the commit message doesn't explain the rationale for that at all.,non-technical
"This makes no sense, cfr my comment on 5/5. Seems like if the driver doesn't implement those, the core can easily detect that and perform the necessary action. Moving the checks out of core seems like the wrong thing to do, rather you should enhance the checks in core if they're insufficient in my opinion.",non-technical
"The core can very well check if these functions are not populated and return ENOSYS So you remove all NULL pointer checks ? Esp. in security-sensitive code? What is the impact of this non-critical path code on performance? Come on ...You can very well impose that in the core, except you don't duplicate the code.",non-technical
"Why you want checks for something that not exist ? Those without them will not work and will do Oops in crypto testmgr,so such drivers should not be used nor accepted in drivers/crypto Ask yourself why crypto do not check for NULL in ahash digest or other required ahash functions. Now size of crypto core is reduced.-",non-technical
"Are you suggesting that the kernel code should NOT perform NULL pointerchecks ? Are you suggesting each driver should implement every single callback available and if it is not implemented, return -ENOSYS ? This looks like a MASSIVE code duplication. You implemented the same code thrice, it surely is not reduced.",non-technical
"You can compile kernel with generic config and at that point you have all the duplicated code stored on your machine. But this discussion is moving away from the point I was concerned about -- that this patchset increases  code duplication and I find this wrong. It does NOT reduce the binary size, just try compiling all the drivers in and it will make the kernel bigger.",non-technical
"It is source code duplication. One do not load all crypto drivers at once, simple because one board has only one crypto HW (or few closely related), and if one even try, almost none of them will initialize on given hardware. E.g. on Exynos board only exynos drivers will load, on board with omap crypto only omap crypto will load. As I said above, it reduces binary size at cost of more source code in few drivers.",non-technical
"wrote: Then, I am wondering why we are holding mmap sem when calling migrate pages() in existing code. Sorry, I missed that. If mmap sem is not needed for migrate pages(), please ignore this patch.",non-technical
Use normal patch styles. Fix your tools before you send any more patches.,non-technical
"While we do not mind cleanup patches, the way you post them (one fix per file) is really annoying and takes us too much time to review. I'll take the ""Fix a possible null pointer"" patch since it is an actual bug fix, but will reject the others, not just this driver but all of them that are currently pendingin our patchwork. Feel free to repost, but only if you organize the patch as either fixing the same type of issue for a whole subdirectory (media/usb, media/pci, etc) or fixing all issues for a single driver. Actual bug fixes (like the null pointer patch in this series) can still be posted as separate patches, but cleanups shouldn't. So in this particular case I would expect two omap vout patches: one for the bug fix, one for the cleanups. Just so you know, I'll reject any future patch series that do not follow these rules. Just use common sense when posting these things in the future. I would also suggest that your time might be spent more productively if you would work on some more useful projects. There is more than enough to do. However, that's up to you.",non-technical
Would you like to answer my still remaining questions in any more constructive ways? ,non-technical
"I did that: either one patch per directory with the same type of change, or one patch per driver combining all the changes for that driver. Yes, and you were told not to do it like that again.",non-technical
Are you going to answer any of my remaining questions in a more constructive way? ,non-technical
Do any contributors get into the mood to take another look at software updates from my selection of change possibilities in a more constructive way? Do you need any additional development resources?,non-technical
"One last time: either post per-driver patches with all the cleanups for a driver in a single patch, or a per-directory patch doing the same cleanup for all drivers in that directory. I prefer the first approach, but it's up to you. We don't have the time to wade through dozens of one-liner cleanup patches. I don't understand what is so difficult about this.",non-technical
"I preferred to offer source code adjustments according to specific transformation patterns mostly for each software module separately (also in small patch series).I am curious if bigger patch packages would be easier to get accepted. Or would you get frightened still by any other change combination? We have got different preferences for a safe patch granularity. I imagine that there are more development factors involved. It is usual that integration of update suggestions will take some time. How would the situation change if I would dare to regroup possible update steps? There are communication difficulties to consider since your terse information from your conference meeting.If you would insist on patch squashing, would you dare to use a development tool like also on your own once more? ",non-technical
I find such a change combination unsafe. Would you dare to apply any (of my) scripts for the semantic patch language directly on the whole directory for multi-media software? Can you handle bigger patches really better than similar patch series? Are there any further possibilities to consider around consequences from a general change resistance? Will any development (or management) tools like make the regrouping of possible update steps more convenient and safer? ,non-technical
Interesting Would you like to share any more information from this meeting? I would appreciate further indications for a corresponding change acceptance. I found a feedback by Mauro Carvalho Chehab more constructive.,non-technical
Thanks for testing this and letting me know.,non-technical
I find it very surprising that you rejected 146 useful update suggestions so easily. What does this software area make it so special in comparison to other Linux subsystems?* Have you taken any other solution approaches into account than  a quick rejection?* Could your reaction have been different if the remarkable number of  change possibilities were sent by different authors (and not only me)?* How should possibly remaining disagreements about affected implementation  details be resolved now?* Are you looking for further improvements around development tools  like patchwork and quilt?* Will you accept increasing risks because of bigger patch sizes?* Can such an information lead to differences in the preferred patch granularity?* How do you think about this detail? How would you ever like to clean up stuff in affected source files which was accumulated (or preserved somehow) over years? I guess that this handling will trigger more communication challenges.Our common sense seems to be occasionally different in significant ways. I distribute my software development capacity over several areas. Does your wording indicate a questionable signal for further contributions? ,non-technical
"Wait, what?  Why would it do that, because it thinks dereferencing NULL is undefined behaviour and it can just do whatever it wants to? That feels crazy, as for these calls we ""know"" it will never be NULL because the previous call to debug fs file get() will always ensure it will be correct. So this is a case of the compiler trying to be smarter than it reallyis, and getting things totally wrong :(Has anyone reported this to the clang developers?Papering over compiler foolishness is not something I like to do in kernel code if at all possible...",non-technical
"A: Because it messes up the order in which people normally read text. Q: Why is top-posting such a bad thing? A: Top-posting. Q: What is the most annoying thing in e-mail?A: No. Q: Should I include quotations after my reply? Then fix the tool, the C code is correct :) Then tell clang not to do that, like we tell gcc not to do that as that is a foolish thing for a compiler to do when building the kernel. ",non-technical
"Wait, clang does not have that?  That's crazy, how has this not been hit yet when building the kernel? ",non-technical
Choose one of those two. Better to keep in order. Ditto. What's wrong with dev info() ? Hmm... Can't you use devm ioremap resources() to get the virtual address for I/O ? When you use explicit casting in printf() you are doing in 99.9% cases something wrong. Noise.,non-technical
"How many times are we going to allow copy-and-pasting the same driver? Last time we wanted to modify the Rockchip driver, we were told ""consolidate"", because ST had already forked our driver. This nearly halted all progress. I'm going to be real disappointed if we see another fork get merged.(IOW, I would say ""over my dead body,"" but I have no power here.) And why can't you use DRM? ",non-technical
"...wait a second...this looks like it's a u-boot driver. There's a surprising amount of similarity between U-boot and Linux drivers (no coincidence I'm sure), including headers.Since when do U-Boot patches go to LKML and dri-devel? Anyway, I'll try my best to ignore this series.",non-technical
"meta comment (i.e., not about the merits of the patch itself): You'll need to send the patch to someone if you want it to be merged. Maintainers don't mine mailing lists for patches to apply.",non-technical
"They've been dropped.  BUT please do note that the patches I pushed tolinux-dm.git were rebased on top of the 'check at most once' patch. I never did get an answer about how the sg array is free'd in certain error paths (see ""FIXME:"" in the 2nd patch). Also, I fixed some issues I saw in error paths, and lots of formatting. I'll be pretty frustrated if you submit v2 that is blind to the kinds of changes I made. I'll send you a private copy of the patches just so you have them for your reference. ",non-technical
"Is this include needed ? Please use bool.I am quite completely missing how the two functions above are different. There is a lot of duplication in those functions. Would it be possible to find common code and use functions for it instead of duplicatingeverything several times ? What if nothing is found ? FWIW, it might be better to pass channel as parameter. What if it didn't find a core ? This attribute should not exist. How does this make sense ? Am I missing something, or is the same temperature reported several times ? tjmax is also reported as this, for example. There is again a lot of duplication in those functions. Can this be made less magic with some defines ? Does this mean there will be an error message for each non-supported CPU? Why? this is not an error, and should not result in an error message. Besides, the error can also be propagated from peci core code, and may well be something else. Then what ? Shouldn't this result in probe deferral or something more useful instead of just being ignored? FWIW, this should be two separate patches. Needed ? It might make sense to provide the duplicate functions in a core file. This again looks like duplicate code. Please handle error cases first. More duplicate code.One set of ( ) is unnecessary on each side of the expression. Why is this ""invalid"", and why does it warrant an error message ? ?Or the peci command failed. ?",non-technical
"Cool. I would say this is done right. How about writing an i2c bus driver which sits directly on top ofanother i2c bus? Basically a one port i2c mux. The current mux code does not seem to directly allow it, since itcalls i2c transfer() directly on the parent, where as you want it to call your own i2c transfer function. But maybe you could expended the core mux code to allow the i2c mux core structure to contain a transfer function?",non-technical
